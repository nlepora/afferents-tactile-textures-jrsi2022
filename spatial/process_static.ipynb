{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process static tactile data\n",
    "* Features are SA and FA firing over a single frame, saved as two arrays:\n",
    "*        feature_SA and features_RA of shape (n_pins, n_pins)\n",
    "* n_pins is number of pins along side of square array (here 19)\n",
    "* Split into train, validation and test sets\n",
    "* For each speed, make distinct training set with that speed left out but retained for testing\n",
    "* Spatial/static uses single samples/frames. Labels are the texture (here 13)\n",
    "\n",
    "To run, first edit dir_data to path where data is stored; preprocess/process should be run first. \n",
    "\n",
    "Because of the large amount of data, a temporary folder is used for the training data, so it can be deleted after training the static model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def open_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = os.environ[\"DATAPATH\"] + r\"/open/afferents-tactile-textures-jrsi2022\"\n",
    "dir_temp = os.environ[\"TEMPPATH\"] \n",
    "\n",
    "dir_train = dir_temp + r\"/static\"\n",
    "dir_test = dir_data + r\"/static\"\n",
    "\n",
    "speeds = ['10','20','30','40','50','60','70','80','90','100']\n",
    "textures = ['0','0.5','1','1.5','2','2.5','3','3.5','4','4.5','5','5.5','6']\n",
    "n_textures = len(textures)\n",
    "n_speeds = len(speeds)\n",
    "\n",
    "firing_SA = open_obj(dir_data + r\"/firing_SA\")\n",
    "firing_RA = open_obj(dir_data + r\"/firing_RA\")\n",
    "pins = open_obj(dir_data + rf\"/pins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_pins(pins, theta):\n",
    "    R = np.array(((np.cos(theta),-np.sin(theta)), (np.sin(theta), np.cos(theta))))\n",
    "    pins_rot = [np.matmul(R, pin) for pin in pins]\n",
    "    return np.array(pins_rot)\n",
    "\n",
    "def locate_pins(pins, n_pins):\n",
    "    locs = np.zeros((n_pins, n_pins))\n",
    "    index_xSort = np.argsort(pins[:,0], axis=0)\n",
    "    \n",
    "    index_ySort = np.zeros((n_pins, n_pins))\n",
    "    n = 0\n",
    "    for k in range(n_pins):\n",
    "        indices = np.zeros((n_pins,2))\n",
    "        for l in range(n_pins):\n",
    "            indices[l,:] = pins[index_xSort[n],:]\n",
    "            n+=1\n",
    "        index_ySort[k,:] = np.argsort(indices[:,1], axis=0)\n",
    "\n",
    "    for k in range(n_pins):\n",
    "        for l in range(n_pins):\n",
    "            locs[k,l] = index_xSort[int(index_ySort[k,l])+n_pins*k]\n",
    "    return locs\n",
    "\n",
    "def features(firing, locs, i_start, n_samples):\n",
    "    n1_pins, n2_pins = np.shape(locs)\n",
    "    features = np.zeros((n_samples, n1_pins, n2_pins))\n",
    "    for k in range(n1_pins):\n",
    "        for l in range(n2_pins):\n",
    "            n = 0\n",
    "            for m in range(i_start, i_start+n_samples):\n",
    "                features[n,k,l] = firing[m, int(locs[k,l])]  \n",
    "                n+=1   \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "theta = np.radians(-6.2)\n",
    "n_pins = 19\n",
    "i_start = 500\n",
    "n_samples = 5000 \n",
    "\n",
    "pins_rot = [[rotate_pins(pins[i][j], theta) for  j in range(n_speeds)] for i in range(n_textures)]\n",
    "locs_rot = [[locate_pins(pins_rot[i][j], n_pins) for  j in range(n_speeds)] for i in range(n_textures)]\n",
    "features_SA = [[features(firing_SA[i][j], locs_rot[i][j], i_start, n_samples) for j in range(n_speeds)] for i in range(n_textures)]\n",
    "features_RA = [[features(firing_RA[i][j], locs_rot[i][j], i_start, n_samples) for j in range(n_speeds)] for i in range(n_textures)]\n",
    "\n",
    "X_SA = np.swapaxes(np.stack(features_SA), 0, 1) # speeds, textures,....\n",
    "X_RA = np.swapaxes(np.stack(features_RA), 0, 1) # speeds, textures,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = n_samples*n_textures*(n_speeds-1) # leave one speed out\n",
    "n_val = int(n_samples*n_textures/2)\n",
    "n_test = int(n_samples*n_textures/2) # equal val test split\n",
    "\n",
    "os.makedirs(dir_train, exist_ok=True)\n",
    "os.makedirs(dir_test, exist_ok=True)\n",
    "\n",
    "for i in range(n_speeds):\n",
    "    dir_train_i = dir_train + rf\"/{i}\"\n",
    "    dir_test_i = dir_test + rf\"/{i}\"\n",
    "    os.makedirs(dir_train_i, exist_ok=True)\n",
    "    os.makedirs(dir_test_i, exist_ok=True)\n",
    "\n",
    "    X_train_SA, X_train_RA = (np.zeros((n_train, n_pins, n_pins, 1)) for _ in range(2))\n",
    "    X_val_SA, X_val_RA = (np.zeros((n_val, n_pins, n_pins, 1)) for _ in range(2))\n",
    "    X_test_SA, X_test_RA = (np.zeros((n_test, n_pins, n_pins, 1)) for _ in range(2))\n",
    "    y_train_SA_texture, y_train_RA_texture = (np.zeros((n_train, n_textures)) for _ in range(2))\n",
    "    y_train_SA_speed, y_train_RA_speed = (np.zeros((n_train, 1)) for _ in range(2))\n",
    "    y_val_SA_texture, y_val_RA_texture = (np.zeros((n_val, n_textures)) for _ in range(2))\n",
    "    y_val_SA_speed, y_val_RA_speed = (np.zeros((n_val, 1)) for _ in range(2))\n",
    "    y_test_SA_texture, y_test_RA_texture = (np.zeros((n_test, n_textures)) for _ in range(2))\n",
    "    y_test_SA_speed, y_test_RA_speed = (np.zeros((n_test, 1)) for _ in range(2))\n",
    "    \n",
    "    n = 0\n",
    "    for j in range(n_speeds):\n",
    "        if not j==i:\n",
    "            X_train_SA[n*n_textures*n_samples:(n+1)*n_textures*n_samples,...] = np.expand_dims(np.concatenate(X_SA[j,...]), axis=3)\n",
    "            X_train_RA[n*n_textures*n_samples:(n+1)*n_textures*n_samples,...] = np.expand_dims(np.concatenate(X_RA[j,...]), axis=3)\n",
    "            for k in range(n_textures):\n",
    "                y_train_SA_texture[(n*n_textures+k)*n_samples : (n*n_textures+k+1)*n_samples, k] = 1\n",
    "                y_train_RA_texture[(n*n_textures+k)*n_samples : (n*n_textures+k+1)*n_samples, k] = 1\n",
    "                y_train_SA_speed[(n*n_textures+k)*n_samples : (n*n_textures+k+1)*n_samples] = j/n_speeds\n",
    "                y_train_RA_speed[(n*n_textures+k)*n_samples : (n*n_textures+k+1)*n_samples] = j/n_speeds\n",
    "            n+=1\n",
    "        else:\n",
    "            val_ind = range(0,n_samples,2)#np.random.choice(N_samples, int(N_samples/2), replace=False)\n",
    "            n_1 = 0\n",
    "            n_2 = 0\n",
    "            for k in range(n_samples):\n",
    "                if k in val_ind:\n",
    "                    X_val_SA[n_1*n_textures:(n_1+1)*n_textures,...] = np.expand_dims(X_SA[j,:,k,...], axis=3)\n",
    "                    X_val_RA[n_1*n_textures:(n_1+1)*n_textures,...] = np.expand_dims(X_RA[j,:,k,...], axis=3)\n",
    "                    for l in range(n_textures):\n",
    "                        y_val_SA_texture[n_1*n_textures+l,l] = 1\n",
    "                        y_val_RA_texture[n_1*n_textures+l,l] = 1\n",
    "                        y_val_SA_speed[n_1*n_textures+l] = i/n_speeds\n",
    "                        y_val_RA_speed[n_1*n_textures+l] = i/n_speeds\n",
    "                    n_1+=1\n",
    "                else:\n",
    "                    X_test_SA[n_2*n_textures:(n_2+1)*n_textures,...] = np.expand_dims(X_SA[j,:,k,...], axis=3)\n",
    "                    X_test_RA[n_2*n_textures:(n_2+1)*n_textures,...] = np.expand_dims(X_RA[j,:,k,...], axis=3)\n",
    "                    for l in range(n_textures):\n",
    "                        y_test_SA_texture[n_2*n_textures+l,l] = 1\n",
    "                        y_test_RA_texture[n_2*n_textures+l,l] = 1\n",
    "                        y_test_SA_speed[n_2*n_textures+l] = i/n_speeds\n",
    "                        y_test_RA_speed[n_2*n_textures+l] = i/n_speeds\n",
    "                    n_2+=1\n",
    "        \n",
    "    save_obj(X_train_SA, dir_train_i + r\"/X_train_SA\")\n",
    "    save_obj(X_val_SA, dir_train_i + r\"/X_val_SA\")\n",
    "    save_obj(X_test_SA, dir_test_i + r\"/X_test_SA\")\n",
    "\n",
    "    save_obj([y_train_SA_speed, y_train_SA_texture], dir_train_i + r\"/y_train_SA\")\n",
    "    save_obj([y_val_SA_speed, y_val_SA_texture], dir_train_i + r\"/y_val_SA\")\n",
    "    save_obj([y_test_SA_speed, y_test_SA_texture], dir_test_i + r\"/y_test_SA\")\n",
    "\n",
    "    save_obj(X_train_RA, dir_train_i + r\"/X_train_RA\")\n",
    "    save_obj(X_val_RA, dir_train_i + r\"/X_val_RA\")\n",
    "    save_obj(X_test_RA, dir_test_i + r\"/X_test_RA\")\n",
    "\n",
    "    save_obj([y_train_RA_speed, y_train_RA_texture], dir_train_i + r\"/y_train_RA\")\n",
    "    save_obj([y_val_RA_speed, y_val_RA_texture], dir_train_i + r\"/y_val_RA\")\n",
    "    save_obj([y_test_RA_speed, y_test_RA_texture], dir_test_i + r\"/y_test_RA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
