{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process vibration data\n",
    "* Features are FFT of segment of vibration data with n_freqs\n",
    "* Split into train, validation and test sets\n",
    "* For each speed, make distinct training set with that speed left out but retained for testing\n",
    "* Spatial/static uses single samples/frames. Labels are the texture (here 13)\n",
    "\n",
    "To run, first edit dir_data to path where data is stored\n",
    "\n",
    "Because of the large amount of data, a temporary folder is used for the training data, so it can be deleted after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def open_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def getSpectra(samples, s1, s2, sampleRte):\n",
    "    spect = np.fft.fft(samples[s1:s2])\n",
    "    mod = np.sqrt(np.power(spect.real,2)+np.power(spect.imag,2)) \n",
    "    mod_norm = 2*(mod/(s2-s1))\n",
    "    freqs = (np.fft.fftfreq(mod.shape[0]))*sampleRte\n",
    "   \n",
    "    return freqs, mod_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = os.environ[\"DATAPATH\"] + r\"/open/afferents-tactile-textures-jrsi2022\"\n",
    "dir_temp = os.environ[\"TEMPPATH\"] \n",
    "\n",
    "speeds = ['10','20','30','40','50','60','70','80','90','100']\n",
    "textures = ['0','0.5','1','1.5','2','2.5','3','3.5','4','4.5','5','5.5','6']\n",
    "\n",
    "n_speeds = len(speeds)\n",
    "n_textures = len(textures)\n",
    "\n",
    "t_data = 60 # duration of data\n",
    "fs = 44100 # sampling rate per second\n",
    "t_segment = 1 # duration of data segment\n",
    "n_samples = t_segment*fs # number of samples per data segment\n",
    "n_data = 119 # number of data segments per speed & texture (assumes stride 0.5)\n",
    "n_freqs = 4000 # number of FFT samples kept\n",
    "\n",
    "n_train = n_data*(n_speeds-1)*n_textures\n",
    "n_val = int(np.floor(n_data/2))*n_textures\n",
    "n_test = int(np.floor(n_data/2)+1)*n_textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((n_speeds, n_textures, t_data*fs))\n",
    "for i in range(n_speeds):\n",
    "    for j in range(n_textures):\n",
    "        _, wav = wavfile.read(dir_data + rf\"/{textures[j]}/{speeds[i]}/audio.wav\")\n",
    "        data[i,j,:] = wav[-t_data*fs:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "# split into individual samples and perform FFT\n",
    "X_audio = np.zeros((n_speeds, n_textures, n_data, n_samples))\n",
    "X_fft = np.zeros((n_speeds, n_textures, n_data, n_samples))\n",
    "for i in range(n_speeds):\n",
    "    print(i, end=' ')\n",
    "    for j in range(n_textures):\n",
    "        for n, t in enumerate(np.linspace(0, t_data-t_segment, n_data)):\n",
    "            X_audio[i,j,n,:] = data[i,j, int(t*fs) : int(t*fs)+n_samples]\n",
    "            f, X_fft[i,j,n,:] = getSpectra(X_audio[i,j,n,:], 0, len(X_audio[i,j,n,:]), n_samples) # perform FFT\n",
    "\n",
    "# normalise and truncate the FFT\n",
    "X_fft = X_fft[..., :n_freqs]\n",
    "X_fft /= np.amax(X_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(dir_temp + r\"/vibration\", exist_ok=True)\n",
    "os.makedirs(dir_data + r\"/processed/vibration\", exist_ok=True)\n",
    "\n",
    "for i in range(n_speeds): \n",
    "    dir_train_i = dir_temp + rf\"/vibration/{i}\"\n",
    "    dir_test_i = dir_data + rf\"/processed/vibration/{i}\"\n",
    "    os.makedirs(dir_train_i, exist_ok=True)\n",
    "    os.makedirs(dir_test_i, exist_ok=True)\n",
    "\n",
    "    X_train = np.zeros((n_train, n_freqs))\n",
    "    X_val = np.zeros((n_val, n_freqs))\n",
    "    X_test = np.zeros((n_test, n_freqs))  \n",
    "\n",
    "    y_train_texture = np.zeros((n_train, n_textures))\n",
    "    y_val_texture = np.zeros((n_val, n_textures))\n",
    "    y_test_texture = np.zeros((n_test, n_textures))\n",
    "    \n",
    "    y_train_speed = np.zeros((n_train, 1))    \n",
    "    y_val_speed = np.zeros((n_val, 1))\n",
    "    y_test_speed = np.zeros((n_test, 1))\n",
    "    \n",
    "    n = 0\n",
    "    for j in range(n_speeds):\n",
    "        if not j==i:\n",
    "            X_train[n*n_data*n_textures : (n+1)*n_data*n_textures, :] = np.concatenate(X_fft[j,:,:,:])\n",
    "            for k in range(n_textures):\n",
    "                y_train_texture[n_data*(n*n_textures+k) : n_data*(n*n_textures+k+1), k] = 1\n",
    "                y_train_speed[n_data*(n*n_textures+k) : n_data*(n*n_textures+k+1)] = j/10\n",
    "            n+=1\n",
    "        else:\n",
    "            val_ind = np.random.choice(n_data, int(np.floor(n_data/2)), replace=False)\n",
    "            n_1 = 0\n",
    "            n_2 = 0\n",
    "            for k in range(n_data):\n",
    "                if k in val_ind:\n",
    "                    X_val[n_1*n_textures:(n_1+1)*n_textures,:] = X_fft[j,:,k,:]\n",
    "                    for l in range(n_textures):\n",
    "                        y_val_texture[n_1*n_textures+l,l] = 1\n",
    "                        y_val_speed[n_1*n_textures+l] = i/n_speeds\n",
    "                    n_1+=1\n",
    "                else:\n",
    "                    X_test[n_2*n_textures:(n_2+1)*n_textures,:] = X_fft[j,:,k,:]\n",
    "                    for l in range(n_textures):\n",
    "                        y_test_texture[n_2*n_textures+l,l] = 1\n",
    "                        y_test_speed[n_2*n_textures+l] = i/n_speeds\n",
    "                    n_2+=1        \n",
    "                    \n",
    "    save_obj(X_train, dir_train_i + r\"/X_train\")\n",
    "    save_obj(X_val, dir_train_i + r\"/X_val\")\n",
    "    save_obj(X_test, dir_test_i + r\"/X_test\")\n",
    "    \n",
    "    save_obj(y_train_texture, dir_train_i + r\"/y_train\")\n",
    "    save_obj(y_val_texture, dir_train_i + r\"/y_val\")\n",
    "    save_obj(y_test_texture, dir_test_i + r\"/y_test\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec9934d05f2433ac775bd4943a80c56f88370a8daa9f676a715cc5a3d6479729"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tactip': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
