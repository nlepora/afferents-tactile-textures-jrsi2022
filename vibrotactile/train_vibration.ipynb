{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prediction models for texture \n",
    "* Convolutional neural network over samples; input frequency spectra of microphone data                \n",
    "* training data concatenated over speed leaving one speed out but retained for testing\n",
    "* therefore total of n_speed models (here 10), one per speed\n",
    "* i.e. prediction of texture independent of held-out speed\n",
    "* data augemnted by stretching or squashing the ffts\n",
    "\n",
    "To run, first edit dir_data to path where data is stored; spaital/process_vibration in this directory should be run first.\n",
    "\n",
    "Because of the large amount of data, a temporary folder is used for the training data, so it can be deleted after training the dynamic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def open_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = os.environ[\"DATAPATH\"] + r\"/open/afferents-tactile-textures-jrsi2022\"\n",
    "dir_temp = os.environ[\"TEMPPATH\"] + r\"/vibration\"\n",
    "\n",
    "n_textures = 13\n",
    "n_speeds = 10\n",
    "fs = 44100 # sampling rate per second\n",
    "n_data = 119 # number of data segments per speed & texture\n",
    "t_segment = 1 # duration of data segment\n",
    "n_samples = t_segment*fs # number of samples per data segment\n",
    "n_freqs = 4000\n",
    "n_features = 200 # freqs to keep as features \n",
    "n_train = n_data*(n_speeds-1)*n_textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session\n",
    "from keras import optimizers, regularizers, callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, BatchNormalization\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(X_train, y_train, X_val, y_val, es, cp):  \n",
    "    clear_session()\n",
    "    \n",
    "    config = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)) # , device_count = {'GPU': 1})\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    set_session(session)\n",
    "    \n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, 5, activation='relu', padding = \"same\", input_shape=(n_features,1)))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(128, 5, activation='relu', padding = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(128, 5, activation='relu', padding = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(128, 5, activation='relu', padding = \"valid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "    model.add(Dense(n_textures, activation='softmax'))#)kernel_regularizer=regularizers.l2(0.005), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=150, batch_size=64, shuffle=True, callbacks=[es,cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 8s 566us/step - loss: 2.0053 - accuracy: 0.4398 - val_loss: 3.9021 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 1.1515 - accuracy: 0.7361 - val_loss: 6.0583 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.8158 - accuracy: 0.8461 - val_loss: 6.6924 - val_accuracy: 0.0769\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.6284 - accuracy: 0.9015 - val_loss: 3.7085 - val_accuracy: 0.1186\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.5228 - accuracy: 0.9316 - val_loss: 3.6717 - val_accuracy: 0.1160\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.4471 - accuracy: 0.9510 - val_loss: 3.8655 - val_accuracy: 0.1199\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 211us/step - loss: 0.3944 - accuracy: 0.9629 - val_loss: 3.6697 - val_accuracy: 0.1382\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.3530 - accuracy: 0.9721 - val_loss: 3.4125 - val_accuracy: 0.1408\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3158 - accuracy: 0.9807 - val_loss: 3.6182 - val_accuracy: 0.1473\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2906 - accuracy: 0.9836 - val_loss: 3.6004 - val_accuracy: 0.1499\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2673 - accuracy: 0.9861 - val_loss: 3.8908 - val_accuracy: 0.1395\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2475 - accuracy: 0.9892 - val_loss: 4.0507 - val_accuracy: 0.1356\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.2265 - accuracy: 0.9916 - val_loss: 3.5464 - val_accuracy: 0.1604\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2089 - accuracy: 0.9932 - val_loss: 3.8283 - val_accuracy: 0.1226\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1923 - accuracy: 0.9948 - val_loss: 3.9372 - val_accuracy: 0.1291\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1808 - accuracy: 0.9938 - val_loss: 3.4586 - val_accuracy: 0.1877\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.1616 - accuracy: 0.9966 - val_loss: 3.5534 - val_accuracy: 0.1473\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1522 - accuracy: 0.9955 - val_loss: 3.7614 - val_accuracy: 0.1369\n",
      "Epoch 19/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.1377 - accuracy: 0.9969 - val_loss: 3.8513 - val_accuracy: 0.1656\n",
      "Epoch 20/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1248 - accuracy: 0.9983 - val_loss: 3.8140 - val_accuracy: 0.1499\n",
      "Epoch 21/150\n",
      "13923/13923 [==============================] - 3s 196us/step - loss: 0.1161 - accuracy: 0.9974 - val_loss: 4.2990 - val_accuracy: 0.1056\n",
      "Epoch 22/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.1066 - accuracy: 0.9978 - val_loss: 3.9754 - val_accuracy: 0.1330\n",
      "Epoch 23/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.0973 - accuracy: 0.9984 - val_loss: 3.7910 - val_accuracy: 0.1447\n",
      "Epoch 24/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.0878 - accuracy: 0.9991 - val_loss: 3.8813 - val_accuracy: 0.1421\n",
      "Epoch 25/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.0804 - accuracy: 0.9996 - val_loss: 3.8818 - val_accuracy: 0.1760\n",
      "Epoch 26/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.0748 - accuracy: 0.9989 - val_loss: 3.6620 - val_accuracy: 0.1851\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 251us/step - loss: 2.0398 - accuracy: 0.4243 - val_loss: 3.9939 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 1.2222 - accuracy: 0.7044 - val_loss: 5.9286 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 196us/step - loss: 0.9073 - accuracy: 0.8108 - val_loss: 5.3043 - val_accuracy: 0.1434\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.7287 - accuracy: 0.8650 - val_loss: 2.3653 - val_accuracy: 0.3481\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.6154 - accuracy: 0.8976 - val_loss: 2.2628 - val_accuracy: 0.3494\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.5342 - accuracy: 0.9205 - val_loss: 2.3041 - val_accuracy: 0.3481\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.4716 - accuracy: 0.9369 - val_loss: 2.4579 - val_accuracy: 0.3351\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.4326 - accuracy: 0.9453 - val_loss: 2.6481 - val_accuracy: 0.3533\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3890 - accuracy: 0.9560 - val_loss: 2.2854 - val_accuracy: 0.3729\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.3599 - accuracy: 0.9618 - val_loss: 2.3291 - val_accuracy: 0.3807\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 206us/step - loss: 0.3313 - accuracy: 0.9655 - val_loss: 2.6821 - val_accuracy: 0.3611\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 207us/step - loss: 0.3084 - accuracy: 0.9703 - val_loss: 2.8086 - val_accuracy: 0.3442\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2889 - accuracy: 0.9727 - val_loss: 2.5453 - val_accuracy: 0.3742\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2691 - accuracy: 0.9755 - val_loss: 2.9761 - val_accuracy: 0.3364\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2503 - accuracy: 0.9777 - val_loss: 2.7366 - val_accuracy: 0.3833\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2336 - accuracy: 0.9804 - val_loss: 2.5988 - val_accuracy: 0.3690\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2200 - accuracy: 0.9806 - val_loss: 2.7108 - val_accuracy: 0.3638\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2052 - accuracy: 0.9818 - val_loss: 3.0927 - val_accuracy: 0.3651\n",
      "Epoch 19/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1895 - accuracy: 0.9858 - val_loss: 2.6777 - val_accuracy: 0.3807\n",
      "Epoch 20/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.1803 - accuracy: 0.9846 - val_loss: 2.9951 - val_accuracy: 0.3468\n",
      "Epoch 21/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1680 - accuracy: 0.9859 - val_loss: 2.9741 - val_accuracy: 0.3572\n",
      "Epoch 22/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1558 - accuracy: 0.9873 - val_loss: 3.0164 - val_accuracy: 0.3272\n",
      "Epoch 23/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.1503 - accuracy: 0.9866 - val_loss: 2.6396 - val_accuracy: 0.3638\n",
      "Epoch 24/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1399 - accuracy: 0.9887 - val_loss: 2.9520 - val_accuracy: 0.3937\n",
      "Epoch 25/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.1303 - accuracy: 0.9905 - val_loss: 2.9210 - val_accuracy: 0.3716\n",
      "Epoch 26/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1265 - accuracy: 0.9893 - val_loss: 2.9543 - val_accuracy: 0.3872\n",
      "Epoch 27/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.1161 - accuracy: 0.9908 - val_loss: 2.9279 - val_accuracy: 0.3572\n",
      "Epoch 28/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.1104 - accuracy: 0.9907 - val_loss: 3.0015 - val_accuracy: 0.3507\n",
      "Epoch 29/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.1003 - accuracy: 0.9931 - val_loss: 2.9626 - val_accuracy: 0.3716\n",
      "Epoch 30/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.0972 - accuracy: 0.9926 - val_loss: 3.0918 - val_accuracy: 0.3585\n",
      "Epoch 31/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.0947 - accuracy: 0.9919 - val_loss: 2.7671 - val_accuracy: 0.3611\n",
      "Epoch 32/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.0844 - accuracy: 0.9950 - val_loss: 2.7484 - val_accuracy: 0.3911\n",
      "Epoch 33/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.0789 - accuracy: 0.9950 - val_loss: 2.8274 - val_accuracy: 0.3520\n",
      "Epoch 34/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.0772 - accuracy: 0.9953 - val_loss: 2.9071 - val_accuracy: 0.3572\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 250us/step - loss: 2.0522 - accuracy: 0.4244 - val_loss: 4.2750 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 1.2242 - accuracy: 0.7118 - val_loss: 6.9477 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.8988 - accuracy: 0.8176 - val_loss: 5.1247 - val_accuracy: 0.1512\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.7227 - accuracy: 0.8714 - val_loss: 2.2426 - val_accuracy: 0.3572\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.6111 - accuracy: 0.9040 - val_loss: 2.2804 - val_accuracy: 0.3533\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.5335 - accuracy: 0.9239 - val_loss: 2.2862 - val_accuracy: 0.3611\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.4753 - accuracy: 0.9379 - val_loss: 2.3973 - val_accuracy: 0.3716\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.4347 - accuracy: 0.9450 - val_loss: 2.3281 - val_accuracy: 0.3937\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 205us/step - loss: 0.4001 - accuracy: 0.9532 - val_loss: 2.8110 - val_accuracy: 0.3716\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 205us/step - loss: 0.3659 - accuracy: 0.9577 - val_loss: 2.7278 - val_accuracy: 0.3585\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3389 - accuracy: 0.9654 - val_loss: 2.6159 - val_accuracy: 0.3781\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3141 - accuracy: 0.9670 - val_loss: 2.6469 - val_accuracy: 0.3611\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2924 - accuracy: 0.9714 - val_loss: 2.7893 - val_accuracy: 0.3455\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2765 - accuracy: 0.9727 - val_loss: 2.9536 - val_accuracy: 0.3455\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2514 - accuracy: 0.9780 - val_loss: 2.9036 - val_accuracy: 0.3625\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.2415 - accuracy: 0.9760 - val_loss: 2.7342 - val_accuracy: 0.3351\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2261 - accuracy: 0.9790 - val_loss: 2.7809 - val_accuracy: 0.3259\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2102 - accuracy: 0.9825 - val_loss: 2.7949 - val_accuracy: 0.3807\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 250us/step - loss: 2.0856 - accuracy: 0.4059 - val_loss: 3.8067 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 1.2707 - accuracy: 0.6905 - val_loss: 4.8649 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.9449 - accuracy: 0.7979 - val_loss: 3.6249 - val_accuracy: 0.1473\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.7542 - accuracy: 0.8619 - val_loss: 1.8077 - val_accuracy: 0.4798\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.6438 - accuracy: 0.8893 - val_loss: 2.0184 - val_accuracy: 0.4654\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.5601 - accuracy: 0.9130 - val_loss: 1.8546 - val_accuracy: 0.4798\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.4974 - accuracy: 0.9278 - val_loss: 2.0586 - val_accuracy: 0.4563\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.4534 - accuracy: 0.9369 - val_loss: 2.2001 - val_accuracy: 0.4889\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.4103 - accuracy: 0.9490 - val_loss: 2.0401 - val_accuracy: 0.5137\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3825 - accuracy: 0.9550 - val_loss: 1.9453 - val_accuracy: 0.4889\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3507 - accuracy: 0.9614 - val_loss: 2.0749 - val_accuracy: 0.5020\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3270 - accuracy: 0.9636 - val_loss: 2.1455 - val_accuracy: 0.5267\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3031 - accuracy: 0.9693 - val_loss: 2.1098 - val_accuracy: 0.4980\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2835 - accuracy: 0.9722 - val_loss: 2.1738 - val_accuracy: 0.4824\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2642 - accuracy: 0.9761 - val_loss: 2.2903 - val_accuracy: 0.4615\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2499 - accuracy: 0.9766 - val_loss: 2.5619 - val_accuracy: 0.4615\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 196us/step - loss: 0.2312 - accuracy: 0.9798 - val_loss: 2.2093 - val_accuracy: 0.4459\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2160 - accuracy: 0.9818 - val_loss: 2.0282 - val_accuracy: 0.4615\n",
      "Epoch 19/150\n",
      "13923/13923 [==============================] - 3s 196us/step - loss: 0.2034 - accuracy: 0.9837 - val_loss: 2.3490 - val_accuracy: 0.4524\n",
      "Epoch 20/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.1902 - accuracy: 0.9841 - val_loss: 2.4682 - val_accuracy: 0.4498\n",
      "Epoch 21/150\n",
      "13923/13923 [==============================] - 3s 196us/step - loss: 0.1807 - accuracy: 0.9846 - val_loss: 2.1692 - val_accuracy: 0.4876\n",
      "Epoch 22/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.1675 - accuracy: 0.9857 - val_loss: 2.3335 - val_accuracy: 0.4993\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 4s 252us/step - loss: 2.0730 - accuracy: 0.4109 - val_loss: 3.9851 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 205us/step - loss: 1.2842 - accuracy: 0.6853 - val_loss: 5.7054 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.9656 - accuracy: 0.7926 - val_loss: 3.8867 - val_accuracy: 0.1773\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.7810 - accuracy: 0.8511 - val_loss: 2.0277 - val_accuracy: 0.4641\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.6590 - accuracy: 0.8844 - val_loss: 2.1230 - val_accuracy: 0.4576\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.5701 - accuracy: 0.9098 - val_loss: 2.0699 - val_accuracy: 0.4967\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.5033 - accuracy: 0.9286 - val_loss: 2.1645 - val_accuracy: 0.4720\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.4578 - accuracy: 0.9373 - val_loss: 2.2846 - val_accuracy: 0.4798\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.4225 - accuracy: 0.9440 - val_loss: 2.3406 - val_accuracy: 0.4720\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3865 - accuracy: 0.9547 - val_loss: 2.4113 - val_accuracy: 0.4563\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3558 - accuracy: 0.9604 - val_loss: 2.3893 - val_accuracy: 0.4707\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3294 - accuracy: 0.9646 - val_loss: 2.4181 - val_accuracy: 0.4654\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3059 - accuracy: 0.9682 - val_loss: 2.5189 - val_accuracy: 0.4524\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2915 - accuracy: 0.9715 - val_loss: 2.5246 - val_accuracy: 0.4498\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2661 - accuracy: 0.9752 - val_loss: 2.6606 - val_accuracy: 0.4420\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.2524 - accuracy: 0.9759 - val_loss: 2.5236 - val_accuracy: 0.4811\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 251us/step - loss: 2.1040 - accuracy: 0.4065 - val_loss: 3.9917 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 1.2935 - accuracy: 0.6826 - val_loss: 5.4082 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.9705 - accuracy: 0.7911 - val_loss: 2.9762 - val_accuracy: 0.1630\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.7812 - accuracy: 0.8535 - val_loss: 1.5617 - val_accuracy: 0.5254\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.6594 - accuracy: 0.8847 - val_loss: 1.4971 - val_accuracy: 0.5306\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.5720 - accuracy: 0.9097 - val_loss: 1.4568 - val_accuracy: 0.5554\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.5084 - accuracy: 0.9266 - val_loss: 1.5029 - val_accuracy: 0.5593\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.4611 - accuracy: 0.9388 - val_loss: 1.6785 - val_accuracy: 0.5346\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.4205 - accuracy: 0.9460 - val_loss: 1.5785 - val_accuracy: 0.5437\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3871 - accuracy: 0.9533 - val_loss: 1.4668 - val_accuracy: 0.5450\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3547 - accuracy: 0.9600 - val_loss: 1.6072 - val_accuracy: 0.5254\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3338 - accuracy: 0.9629 - val_loss: 1.5735 - val_accuracy: 0.5411\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3078 - accuracy: 0.9690 - val_loss: 1.5549 - val_accuracy: 0.5528\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.2879 - accuracy: 0.9711 - val_loss: 1.5990 - val_accuracy: 0.5489\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2664 - accuracy: 0.9752 - val_loss: 1.7510 - val_accuracy: 0.5202\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2539 - accuracy: 0.9753 - val_loss: 1.6722 - val_accuracy: 0.5293\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2379 - accuracy: 0.9768 - val_loss: 1.5107 - val_accuracy: 0.5424\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 4s 253us/step - loss: 2.1111 - accuracy: 0.3943 - val_loss: 3.9110 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 1.3144 - accuracy: 0.6733 - val_loss: 4.8931 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.9858 - accuracy: 0.7828 - val_loss: 2.6959 - val_accuracy: 0.2894\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.7926 - accuracy: 0.8444 - val_loss: 1.9517 - val_accuracy: 0.4537\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.6683 - accuracy: 0.8821 - val_loss: 1.8326 - val_accuracy: 0.5228\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.5710 - accuracy: 0.9104 - val_loss: 1.9287 - val_accuracy: 0.5085\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.5096 - accuracy: 0.9255 - val_loss: 1.9850 - val_accuracy: 0.4902\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.4549 - accuracy: 0.9405 - val_loss: 2.0344 - val_accuracy: 0.5124\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.4185 - accuracy: 0.9484 - val_loss: 2.0573 - val_accuracy: 0.4902\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.3852 - accuracy: 0.9553 - val_loss: 2.2109 - val_accuracy: 0.5059\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.3535 - accuracy: 0.9599 - val_loss: 2.2463 - val_accuracy: 0.4954\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3263 - accuracy: 0.9672 - val_loss: 2.1826 - val_accuracy: 0.4941\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.3045 - accuracy: 0.9707 - val_loss: 2.4163 - val_accuracy: 0.4863\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2908 - accuracy: 0.9702 - val_loss: 2.2969 - val_accuracy: 0.5111\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2671 - accuracy: 0.9754 - val_loss: 2.3578 - val_accuracy: 0.4785\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 249us/step - loss: 2.1443 - accuracy: 0.3837 - val_loss: 3.8029 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 1.3428 - accuracy: 0.6619 - val_loss: 4.1671 - val_accuracy: 0.0952\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 1.0056 - accuracy: 0.7782 - val_loss: 2.0341 - val_accuracy: 0.3585\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.8001 - accuracy: 0.8463 - val_loss: 1.1683 - val_accuracy: 0.6988\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.6733 - accuracy: 0.8881 - val_loss: 1.1610 - val_accuracy: 0.6910\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.5775 - accuracy: 0.9112 - val_loss: 1.1232 - val_accuracy: 0.7132\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.5137 - accuracy: 0.9270 - val_loss: 1.1607 - val_accuracy: 0.6962\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.4612 - accuracy: 0.9394 - val_loss: 1.0647 - val_accuracy: 0.7301\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.4197 - accuracy: 0.9491 - val_loss: 1.2198 - val_accuracy: 0.6819\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.3868 - accuracy: 0.9561 - val_loss: 1.3208 - val_accuracy: 0.6610\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3544 - accuracy: 0.9617 - val_loss: 1.3265 - val_accuracy: 0.6584\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3296 - accuracy: 0.9657 - val_loss: 1.3146 - val_accuracy: 0.6493\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3105 - accuracy: 0.9687 - val_loss: 1.3243 - val_accuracy: 0.6597\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2898 - accuracy: 0.9717 - val_loss: 1.3355 - val_accuracy: 0.6480\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2668 - accuracy: 0.9766 - val_loss: 1.3473 - val_accuracy: 0.6349\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2539 - accuracy: 0.9751 - val_loss: 1.2566 - val_accuracy: 0.6480\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2347 - accuracy: 0.9793 - val_loss: 1.3349 - val_accuracy: 0.6362\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2211 - accuracy: 0.9811 - val_loss: 1.3294 - val_accuracy: 0.6336\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 3s 251us/step - loss: 2.1401 - accuracy: 0.3890 - val_loss: 3.8430 - val_accuracy: 0.1199\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 1.3248 - accuracy: 0.6653 - val_loss: 4.7629 - val_accuracy: 0.0821\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.9866 - accuracy: 0.7860 - val_loss: 2.4499 - val_accuracy: 0.3546\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 204us/step - loss: 0.7901 - accuracy: 0.8487 - val_loss: 1.7009 - val_accuracy: 0.5815\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 204us/step - loss: 0.6638 - accuracy: 0.8834 - val_loss: 1.7874 - val_accuracy: 0.5711\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.5792 - accuracy: 0.9068 - val_loss: 1.7188 - val_accuracy: 0.6023\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.5139 - accuracy: 0.9259 - val_loss: 1.8805 - val_accuracy: 0.5606\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.4640 - accuracy: 0.9379 - val_loss: 1.9336 - val_accuracy: 0.5776\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.4288 - accuracy: 0.9440 - val_loss: 2.0755 - val_accuracy: 0.5450\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.3937 - accuracy: 0.9520 - val_loss: 1.9856 - val_accuracy: 0.5997\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.3652 - accuracy: 0.9570 - val_loss: 2.1020 - val_accuracy: 0.6010\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.3396 - accuracy: 0.9613 - val_loss: 2.0571 - val_accuracy: 0.6076\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 204us/step - loss: 0.3126 - accuracy: 0.9688 - val_loss: 1.9934 - val_accuracy: 0.6375\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.2968 - accuracy: 0.9700 - val_loss: 1.9334 - val_accuracy: 0.5880\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.2762 - accuracy: 0.9723 - val_loss: 2.1478 - val_accuracy: 0.5854\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2631 - accuracy: 0.9744 - val_loss: 2.0608 - val_accuracy: 0.5684\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.2442 - accuracy: 0.9762 - val_loss: 2.1444 - val_accuracy: 0.5789\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2282 - accuracy: 0.9787 - val_loss: 2.0671 - val_accuracy: 0.5997\n",
      "Epoch 19/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2130 - accuracy: 0.9815 - val_loss: 2.1226 - val_accuracy: 0.5841\n",
      "Epoch 20/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2005 - accuracy: 0.9823 - val_loss: 1.8639 - val_accuracy: 0.5854\n",
      "Epoch 21/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.1873 - accuracy: 0.9841 - val_loss: 2.0686 - val_accuracy: 0.6023\n",
      "Epoch 22/150\n",
      "13923/13923 [==============================] - 3s 206us/step - loss: 0.1777 - accuracy: 0.9842 - val_loss: 2.0556 - val_accuracy: 0.6023\n",
      "Epoch 23/150\n",
      "13923/13923 [==============================] - 3s 206us/step - loss: 0.1686 - accuracy: 0.9856 - val_loss: 2.2617 - val_accuracy: 0.6063\n",
      "Train on 13923 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "13923/13923 [==============================] - 4s 254us/step - loss: 2.1430 - accuracy: 0.3859 - val_loss: 3.6756 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 1.3262 - accuracy: 0.6667 - val_loss: 3.9272 - val_accuracy: 0.1408\n",
      "Epoch 3/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 1.0029 - accuracy: 0.7768 - val_loss: 2.1558 - val_accuracy: 0.3598\n",
      "Epoch 4/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.7950 - accuracy: 0.8433 - val_loss: 1.4889 - val_accuracy: 0.5750\n",
      "Epoch 5/150\n",
      "13923/13923 [==============================] - 3s 201us/step - loss: 0.6588 - accuracy: 0.8863 - val_loss: 1.5940 - val_accuracy: 0.6010\n",
      "Epoch 6/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.5750 - accuracy: 0.9099 - val_loss: 1.5927 - val_accuracy: 0.6180\n",
      "Epoch 7/150\n",
      "13923/13923 [==============================] - 3s 202us/step - loss: 0.5067 - accuracy: 0.9268 - val_loss: 1.5628 - val_accuracy: 0.6115\n",
      "Epoch 8/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.4598 - accuracy: 0.9380 - val_loss: 1.3739 - val_accuracy: 0.6323\n",
      "Epoch 9/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.4214 - accuracy: 0.9456 - val_loss: 1.4255 - val_accuracy: 0.6063\n",
      "Epoch 10/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.3884 - accuracy: 0.9539 - val_loss: 1.4177 - val_accuracy: 0.6375\n",
      "Epoch 11/150\n",
      "13923/13923 [==============================] - 3s 203us/step - loss: 0.3569 - accuracy: 0.9592 - val_loss: 1.3185 - val_accuracy: 0.6375\n",
      "Epoch 12/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.3294 - accuracy: 0.9650 - val_loss: 1.4350 - val_accuracy: 0.6232\n",
      "Epoch 13/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.3110 - accuracy: 0.9681 - val_loss: 1.1625 - val_accuracy: 0.6649\n",
      "Epoch 14/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2890 - accuracy: 0.9732 - val_loss: 1.2080 - val_accuracy: 0.6441\n",
      "Epoch 15/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.2664 - accuracy: 0.9762 - val_loss: 1.3366 - val_accuracy: 0.6258\n",
      "Epoch 16/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.2532 - accuracy: 0.9775 - val_loss: 1.4288 - val_accuracy: 0.5932\n",
      "Epoch 17/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.2387 - accuracy: 0.9789 - val_loss: 1.5184 - val_accuracy: 0.5724\n",
      "Epoch 18/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2233 - accuracy: 0.9797 - val_loss: 1.6611 - val_accuracy: 0.5828\n",
      "Epoch 19/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.2108 - accuracy: 0.9813 - val_loss: 1.3580 - val_accuracy: 0.6154\n",
      "Epoch 20/150\n",
      "13923/13923 [==============================] - 3s 198us/step - loss: 0.1926 - accuracy: 0.9849 - val_loss: 1.4855 - val_accuracy: 0.5724\n",
      "Epoch 21/150\n",
      "13923/13923 [==============================] - 3s 200us/step - loss: 0.1839 - accuracy: 0.9852 - val_loss: 1.3891 - val_accuracy: 0.5776\n",
      "Epoch 22/150\n",
      "13923/13923 [==============================] - 3s 199us/step - loss: 0.1701 - accuracy: 0.9875 - val_loss: 1.3805 - val_accuracy: 0.6037\n",
      "Epoch 23/150\n",
      "13923/13923 [==============================] - 3s 197us/step - loss: 0.1622 - accuracy: 0.9865 - val_loss: 1.3514 - val_accuracy: 0.6102\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speeds):\n",
    "    data_set = dir_temp + rf\"/{i}\"\n",
    "    X_train = open_obj(data_set + r\"/X_train\") \n",
    "    y_train = open_obj(data_set + r\"/y_train\")  \n",
    "    X_val = open_obj(data_set + r\"/X_val\")\n",
    "    y_val = open_obj(data_set + r\"/y_val\")\n",
    "\n",
    "    X_train = np.expand_dims(X_train[:,:n_features], axis=2)\n",
    "    X_val = np.expand_dims(X_val[:,:n_features], axis=2)\n",
    "\n",
    "    dir_model = dir_data + rf\"/models/vibration/{i}\"\n",
    "    os.makedirs(dir_model)\n",
    "    cp = callbacks.ModelCheckpoint(dir_model + r\"/model_{epoch:02d}_{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    define_model(X_train, y_train, X_val, y_val, es, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aug = 3 # half stretching/squashing - simulate faster/slower speed\n",
    "\n",
    "def augment(X_train, y_train):\n",
    "    X_train_aug = np.zeros((n_train*2*n_aug, n_features))\n",
    "    y_train_aug = np.zeros((n_train*2*n_aug, n_textures))\n",
    "    stretch = np.concatenate([np.random.uniform(.5,1,(n_aug,n_train)), np.random.uniform(1,2,(n_aug,n_train))])\n",
    "    for i in range(n_train):\n",
    "        for j in range(2*n_aug):\n",
    "            X_train_aug[i*2*n_aug+j,:] = signal.resample(X_train[i,:], int(stretch[j,i]*n_freqs))[:n_features] \n",
    "            y_train_aug[i*2*n_aug+j,:] = y_train[i,:]\n",
    "    return X_train_aug, y_train_aug\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 16s 192us/step - loss: 1.4722 - accuracy: 0.5858 - val_loss: 2.3852 - val_accuracy: 0.2386\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.7681 - accuracy: 0.8153 - val_loss: 2.2558 - val_accuracy: 0.2751\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.5639 - accuracy: 0.8747 - val_loss: 2.0744 - val_accuracy: 0.3233\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.4457 - accuracy: 0.9047 - val_loss: 2.4899 - val_accuracy: 0.2568\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.3680 - accuracy: 0.9216 - val_loss: 2.1872 - val_accuracy: 0.2973\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.3093 - accuracy: 0.9356 - val_loss: 2.0405 - val_accuracy: 0.3794\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2653 - accuracy: 0.9439 - val_loss: 2.0488 - val_accuracy: 0.3872\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.2313 - accuracy: 0.9511 - val_loss: 2.4331 - val_accuracy: 0.3207\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2032 - accuracy: 0.9573 - val_loss: 2.5020 - val_accuracy: 0.3103\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.1817 - accuracy: 0.9622 - val_loss: 2.4752 - val_accuracy: 0.3051\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 15s 179us/step - loss: 0.1620 - accuracy: 0.9669 - val_loss: 2.8589 - val_accuracy: 0.3129\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1466 - accuracy: 0.9702 - val_loss: 2.1635 - val_accuracy: 0.3846\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1332 - accuracy: 0.9733 - val_loss: 2.1987 - val_accuracy: 0.3885\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.1213 - accuracy: 0.9758 - val_loss: 2.1600 - val_accuracy: 0.4237\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.1130 - accuracy: 0.9773 - val_loss: 2.2490 - val_accuracy: 0.4198\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1031 - accuracy: 0.9792 - val_loss: 2.3432 - val_accuracy: 0.3872\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0945 - accuracy: 0.9814 - val_loss: 2.4311 - val_accuracy: 0.3768\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0873 - accuracy: 0.9828 - val_loss: 2.7032 - val_accuracy: 0.3729\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0823 - accuracy: 0.9838 - val_loss: 2.6557 - val_accuracy: 0.3611\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 2.8310 - val_accuracy: 0.3546\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0732 - accuracy: 0.9856 - val_loss: 2.5346 - val_accuracy: 0.3729\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0646 - accuracy: 0.9883 - val_loss: 2.5566 - val_accuracy: 0.3846\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.0635 - accuracy: 0.9882 - val_loss: 2.6385 - val_accuracy: 0.3846\n",
      "Epoch 24/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.0599 - accuracy: 0.9889 - val_loss: 2.4574 - val_accuracy: 0.4081\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.5341 - accuracy: 0.5700 - val_loss: 1.8729 - val_accuracy: 0.4133\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.8555 - accuracy: 0.7865 - val_loss: 1.4516 - val_accuracy: 0.5202\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.6490 - accuracy: 0.8465 - val_loss: 1.3077 - val_accuracy: 0.5450\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.5307 - accuracy: 0.8746 - val_loss: 1.2415 - val_accuracy: 0.5671\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.4506 - accuracy: 0.8942 - val_loss: 1.1822 - val_accuracy: 0.6206\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 180us/step - loss: 0.3921 - accuracy: 0.9063 - val_loss: 0.9332 - val_accuracy: 0.6975\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.3471 - accuracy: 0.9158 - val_loss: 1.0890 - val_accuracy: 0.6154\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.3117 - accuracy: 0.9242 - val_loss: 1.1719 - val_accuracy: 0.5880\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2828 - accuracy: 0.9306 - val_loss: 1.0197 - val_accuracy: 0.6454\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2621 - accuracy: 0.9349 - val_loss: 0.9470 - val_accuracy: 0.6688\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2407 - accuracy: 0.9399 - val_loss: 0.8633 - val_accuracy: 0.7080\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.2219 - accuracy: 0.9446 - val_loss: 0.8894 - val_accuracy: 0.6975\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2110 - accuracy: 0.9462 - val_loss: 0.7896 - val_accuracy: 0.7445\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.1967 - accuracy: 0.9500 - val_loss: 0.9038 - val_accuracy: 0.7053\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1844 - accuracy: 0.9535 - val_loss: 1.0100 - val_accuracy: 0.6884\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1751 - accuracy: 0.9554 - val_loss: 0.9216 - val_accuracy: 0.7106\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1649 - accuracy: 0.9580 - val_loss: 0.7557 - val_accuracy: 0.7340\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1559 - accuracy: 0.9604 - val_loss: 0.8440 - val_accuracy: 0.7210\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1488 - accuracy: 0.9625 - val_loss: 0.7839 - val_accuracy: 0.7275\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1429 - accuracy: 0.9641 - val_loss: 1.3166 - val_accuracy: 0.6245\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1374 - accuracy: 0.9643 - val_loss: 0.8961 - val_accuracy: 0.7093\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.1296 - accuracy: 0.9672 - val_loss: 0.8856 - val_accuracy: 0.7379\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1241 - accuracy: 0.9687 - val_loss: 0.9343 - val_accuracy: 0.7027\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.5796 - accuracy: 0.5487 - val_loss: 1.3888 - val_accuracy: 0.5684\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.8950 - accuracy: 0.7704 - val_loss: 1.1557 - val_accuracy: 0.6375\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.6903 - accuracy: 0.8307 - val_loss: 0.8099 - val_accuracy: 0.7536\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.5705 - accuracy: 0.8594 - val_loss: 0.7480 - val_accuracy: 0.7836\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.4907 - accuracy: 0.8789 - val_loss: 0.6584 - val_accuracy: 0.8018\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.4352 - accuracy: 0.8922 - val_loss: 0.7107 - val_accuracy: 0.7757\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.3815 - accuracy: 0.9045 - val_loss: 0.5377 - val_accuracy: 0.8383\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.3470 - accuracy: 0.9119 - val_loss: 0.5844 - val_accuracy: 0.7914\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.3167 - accuracy: 0.9189 - val_loss: 0.4858 - val_accuracy: 0.8488\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2922 - accuracy: 0.9251 - val_loss: 0.5569 - val_accuracy: 0.8031\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2737 - accuracy: 0.9294 - val_loss: 0.4357 - val_accuracy: 0.8631\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2506 - accuracy: 0.9347 - val_loss: 0.3748 - val_accuracy: 0.8814\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.2382 - accuracy: 0.9379 - val_loss: 0.4594 - val_accuracy: 0.8618\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2236 - accuracy: 0.9413 - val_loss: 0.3684 - val_accuracy: 0.8853\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2097 - accuracy: 0.9461 - val_loss: 0.3963 - val_accuracy: 0.8801\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1974 - accuracy: 0.9483 - val_loss: 0.3234 - val_accuracy: 0.8944\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.1876 - accuracy: 0.9508 - val_loss: 0.3859 - val_accuracy: 0.8735\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1786 - accuracy: 0.9530 - val_loss: 0.4042 - val_accuracy: 0.8814\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1675 - accuracy: 0.9563 - val_loss: 0.5145 - val_accuracy: 0.8370\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1631 - accuracy: 0.9566 - val_loss: 0.4583 - val_accuracy: 0.8435\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1532 - accuracy: 0.9603 - val_loss: 0.3843 - val_accuracy: 0.8644\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1469 - accuracy: 0.9627 - val_loss: 0.3680 - val_accuracy: 0.8814\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1412 - accuracy: 0.9634 - val_loss: 0.4556 - val_accuracy: 0.8540\n",
      "Epoch 24/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1340 - accuracy: 0.9655 - val_loss: 0.4694 - val_accuracy: 0.8644\n",
      "Epoch 25/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.1285 - accuracy: 0.9663 - val_loss: 0.4341 - val_accuracy: 0.8644\n",
      "Epoch 26/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1261 - accuracy: 0.9671 - val_loss: 0.4357 - val_accuracy: 0.8566\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.6000 - accuracy: 0.5410 - val_loss: 1.0686 - val_accuracy: 0.7001\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.9245 - accuracy: 0.7592 - val_loss: 0.7182 - val_accuracy: 0.8057\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.7152 - accuracy: 0.8199 - val_loss: 0.5829 - val_accuracy: 0.8735\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.5967 - accuracy: 0.8518 - val_loss: 0.5102 - val_accuracy: 0.8592\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.5103 - accuracy: 0.8724 - val_loss: 0.4256 - val_accuracy: 0.8970\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 180us/step - loss: 0.4501 - accuracy: 0.8859 - val_loss: 0.3524 - val_accuracy: 0.9153\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.4013 - accuracy: 0.8968 - val_loss: 0.3198 - val_accuracy: 0.9257\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.3620 - accuracy: 0.9072 - val_loss: 0.2794 - val_accuracy: 0.9335\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.3312 - accuracy: 0.9138 - val_loss: 0.3335 - val_accuracy: 0.9087\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.3035 - accuracy: 0.9211 - val_loss: 0.3977 - val_accuracy: 0.8670\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2813 - accuracy: 0.9272 - val_loss: 0.2318 - val_accuracy: 0.9309\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2620 - accuracy: 0.9305 - val_loss: 0.2932 - val_accuracy: 0.9087\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 182us/step - loss: 0.2470 - accuracy: 0.9346 - val_loss: 0.2663 - val_accuracy: 0.9270\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2315 - accuracy: 0.9392 - val_loss: 0.1908 - val_accuracy: 0.9465\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.2168 - accuracy: 0.9433 - val_loss: 0.2444 - val_accuracy: 0.9296\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2059 - accuracy: 0.9467 - val_loss: 0.2875 - val_accuracy: 0.9113\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1950 - accuracy: 0.9486 - val_loss: 0.1993 - val_accuracy: 0.9400\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1861 - accuracy: 0.9514 - val_loss: 0.2051 - val_accuracy: 0.9283\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1754 - accuracy: 0.9544 - val_loss: 0.2020 - val_accuracy: 0.9361\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1687 - accuracy: 0.9555 - val_loss: 0.1961 - val_accuracy: 0.9439\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1597 - accuracy: 0.9588 - val_loss: 0.2412 - val_accuracy: 0.9257\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1524 - accuracy: 0.9600 - val_loss: 0.2571 - val_accuracy: 0.9205\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1457 - accuracy: 0.9624 - val_loss: 0.2766 - val_accuracy: 0.9100\n",
      "Epoch 24/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1408 - accuracy: 0.9639 - val_loss: 0.2141 - val_accuracy: 0.9205\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.6163 - accuracy: 0.5352 - val_loss: 0.8105 - val_accuracy: 0.8136\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.9519 - accuracy: 0.7463 - val_loss: 0.5067 - val_accuracy: 0.9100\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.7392 - accuracy: 0.8105 - val_loss: 0.4036 - val_accuracy: 0.9322\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.6134 - accuracy: 0.8456 - val_loss: 0.3124 - val_accuracy: 0.9465\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.5286 - accuracy: 0.8651 - val_loss: 0.2487 - val_accuracy: 0.9635\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 183us/step - loss: 0.4679 - accuracy: 0.8795 - val_loss: 0.2250 - val_accuracy: 0.9661\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 180us/step - loss: 0.4157 - accuracy: 0.8933 - val_loss: 0.2227 - val_accuracy: 0.9596\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.3776 - accuracy: 0.9021 - val_loss: 0.1801 - val_accuracy: 0.9765\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.3448 - accuracy: 0.9106 - val_loss: 0.1579 - val_accuracy: 0.9791\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 179us/step - loss: 0.3174 - accuracy: 0.9176 - val_loss: 0.3061 - val_accuracy: 0.9009\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2951 - accuracy: 0.9223 - val_loss: 0.2182 - val_accuracy: 0.9570\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2724 - accuracy: 0.9280 - val_loss: 0.1435 - val_accuracy: 0.9700\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2584 - accuracy: 0.9314 - val_loss: 0.1402 - val_accuracy: 0.9661\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 14s 174us/step - loss: 0.2428 - accuracy: 0.9356 - val_loss: 0.1346 - val_accuracy: 0.9739\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2283 - accuracy: 0.9393 - val_loss: 0.1545 - val_accuracy: 0.9752\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2171 - accuracy: 0.9425 - val_loss: 0.2202 - val_accuracy: 0.9335\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 174us/step - loss: 0.2043 - accuracy: 0.9461 - val_loss: 0.1169 - val_accuracy: 0.9739\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 174us/step - loss: 0.1953 - accuracy: 0.9482 - val_loss: 0.1155 - val_accuracy: 0.9791\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1850 - accuracy: 0.9515 - val_loss: 0.1205 - val_accuracy: 0.9765\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.6179 - accuracy: 0.5343 - val_loss: 0.6332 - val_accuracy: 0.9048\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.9583 - accuracy: 0.7459 - val_loss: 0.4319 - val_accuracy: 0.9505\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.7439 - accuracy: 0.8093 - val_loss: 0.3192 - val_accuracy: 0.9648\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.6148 - accuracy: 0.8457 - val_loss: 0.2343 - val_accuracy: 0.9844\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.5299 - accuracy: 0.8675 - val_loss: 0.2081 - val_accuracy: 0.9713\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 183us/step - loss: 0.4669 - accuracy: 0.8825 - val_loss: 0.1840 - val_accuracy: 0.9831\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.4161 - accuracy: 0.8941 - val_loss: 0.1422 - val_accuracy: 0.9883\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.3741 - accuracy: 0.9038 - val_loss: 0.1291 - val_accuracy: 0.9844\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.3437 - accuracy: 0.9115 - val_loss: 0.1193 - val_accuracy: 0.9857\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.3155 - accuracy: 0.9191 - val_loss: 0.1114 - val_accuracy: 0.9883\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2935 - accuracy: 0.9241 - val_loss: 0.1113 - val_accuracy: 0.9857\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2725 - accuracy: 0.9290 - val_loss: 0.0861 - val_accuracy: 0.9935\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.2576 - accuracy: 0.9324 - val_loss: 0.1027 - val_accuracy: 0.9844\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2395 - accuracy: 0.9383 - val_loss: 0.0913 - val_accuracy: 0.9857\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2253 - accuracy: 0.9412 - val_loss: 0.0660 - val_accuracy: 0.9948\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.2154 - accuracy: 0.9436 - val_loss: 0.0824 - val_accuracy: 0.9909\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.2013 - accuracy: 0.9476 - val_loss: 0.0899 - val_accuracy: 0.9844\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1932 - accuracy: 0.9494 - val_loss: 0.0678 - val_accuracy: 0.9909\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1826 - accuracy: 0.9523 - val_loss: 0.0672 - val_accuracy: 0.9883\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1767 - accuracy: 0.9533 - val_loss: 0.0613 - val_accuracy: 0.9922\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1673 - accuracy: 0.9561 - val_loss: 0.0576 - val_accuracy: 0.9948\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.1591 - accuracy: 0.9585 - val_loss: 0.0645 - val_accuracy: 0.9909\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 14s 174us/step - loss: 0.1536 - accuracy: 0.9596 - val_loss: 0.0524 - val_accuracy: 0.9909\n",
      "Epoch 24/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1480 - accuracy: 0.9609 - val_loss: 0.0685 - val_accuracy: 0.9857\n",
      "Epoch 25/150\n",
      "83538/83538 [==============================] - 14s 173us/step - loss: 0.1418 - accuracy: 0.9627 - val_loss: 0.1048 - val_accuracy: 0.9778\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 183us/step - loss: 1.6173 - accuracy: 0.5347 - val_loss: 0.6239 - val_accuracy: 0.8814\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.9539 - accuracy: 0.7466 - val_loss: 0.3553 - val_accuracy: 0.9700\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.7408 - accuracy: 0.8110 - val_loss: 0.2726 - val_accuracy: 0.9804\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.6139 - accuracy: 0.8449 - val_loss: 0.2242 - val_accuracy: 0.9817\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.5292 - accuracy: 0.8663 - val_loss: 0.1878 - val_accuracy: 0.9844\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.4687 - accuracy: 0.8793 - val_loss: 0.1563 - val_accuracy: 0.9857\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.4158 - accuracy: 0.8941 - val_loss: 0.1280 - val_accuracy: 0.9922\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.3780 - accuracy: 0.9025 - val_loss: 0.1191 - val_accuracy: 0.9909\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.3459 - accuracy: 0.9104 - val_loss: 0.1056 - val_accuracy: 0.9883\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.3195 - accuracy: 0.9162 - val_loss: 0.1015 - val_accuracy: 0.9922\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2971 - accuracy: 0.9224 - val_loss: 0.1011 - val_accuracy: 0.9909\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2752 - accuracy: 0.9283 - val_loss: 0.0874 - val_accuracy: 0.9896\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2601 - accuracy: 0.9311 - val_loss: 0.0934 - val_accuracy: 0.9896\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2459 - accuracy: 0.9350 - val_loss: 0.0951 - val_accuracy: 0.9857\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2316 - accuracy: 0.9376 - val_loss: 0.0767 - val_accuracy: 0.9883\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2192 - accuracy: 0.9424 - val_loss: 0.0829 - val_accuracy: 0.9883\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2044 - accuracy: 0.9456 - val_loss: 0.0872 - val_accuracy: 0.9883\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 185us/step - loss: 1.6352 - accuracy: 0.5248 - val_loss: 0.6110 - val_accuracy: 0.8905\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.9679 - accuracy: 0.7409 - val_loss: 0.3791 - val_accuracy: 0.9531\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.7505 - accuracy: 0.8081 - val_loss: 0.2807 - val_accuracy: 0.9713\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.6197 - accuracy: 0.8437 - val_loss: 0.2203 - val_accuracy: 0.9870\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.5348 - accuracy: 0.8655 - val_loss: 0.1775 - val_accuracy: 0.9870\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 183us/step - loss: 0.4696 - accuracy: 0.8813 - val_loss: 0.1518 - val_accuracy: 0.9922\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 15s 179us/step - loss: 0.4175 - accuracy: 0.8945 - val_loss: 0.1239 - val_accuracy: 0.9987\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 179us/step - loss: 0.3763 - accuracy: 0.9037 - val_loss: 0.1150 - val_accuracy: 0.9948\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.3463 - accuracy: 0.9103 - val_loss: 0.0961 - val_accuracy: 0.9987\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.3179 - accuracy: 0.9172 - val_loss: 0.0909 - val_accuracy: 0.9961\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2943 - accuracy: 0.9226 - val_loss: 0.0824 - val_accuracy: 0.9961\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.2729 - accuracy: 0.9288 - val_loss: 0.0848 - val_accuracy: 0.9922\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.2553 - accuracy: 0.9337 - val_loss: 0.0788 - val_accuracy: 0.9935\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2401 - accuracy: 0.9371 - val_loss: 0.0785 - val_accuracy: 0.9935\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2280 - accuracy: 0.9392 - val_loss: 0.0704 - val_accuracy: 0.9948\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.2159 - accuracy: 0.9435 - val_loss: 0.0691 - val_accuracy: 0.9948\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.2044 - accuracy: 0.9463 - val_loss: 0.0665 - val_accuracy: 0.9896\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 182us/step - loss: 1.6329 - accuracy: 0.5254 - val_loss: 0.6068 - val_accuracy: 0.8931\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 175us/step - loss: 0.9726 - accuracy: 0.7393 - val_loss: 0.3643 - val_accuracy: 0.9596\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.7540 - accuracy: 0.8076 - val_loss: 0.2470 - val_accuracy: 0.9922\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.6259 - accuracy: 0.8410 - val_loss: 0.2023 - val_accuracy: 0.9896\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 15s 174us/step - loss: 0.5360 - accuracy: 0.8644 - val_loss: 0.1610 - val_accuracy: 0.9961\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 178us/step - loss: 0.4724 - accuracy: 0.8790 - val_loss: 0.1488 - val_accuracy: 0.9909\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.4194 - accuracy: 0.8932 - val_loss: 0.1116 - val_accuracy: 0.9987\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.3795 - accuracy: 0.9017 - val_loss: 0.1228 - val_accuracy: 0.9987\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.3482 - accuracy: 0.9100 - val_loss: 0.0925 - val_accuracy: 0.9961\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.3211 - accuracy: 0.9171 - val_loss: 0.0770 - val_accuracy: 0.9987\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2984 - accuracy: 0.9218 - val_loss: 0.0801 - val_accuracy: 0.9974\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2745 - accuracy: 0.9289 - val_loss: 0.0693 - val_accuracy: 0.9974\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2596 - accuracy: 0.9317 - val_loss: 0.0692 - val_accuracy: 0.9948\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.2445 - accuracy: 0.9363 - val_loss: 0.0613 - val_accuracy: 0.9974\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2318 - accuracy: 0.9386 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.2186 - accuracy: 0.9430 - val_loss: 0.0551 - val_accuracy: 0.9974\n",
      "Epoch 17/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.2044 - accuracy: 0.9461 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1941 - accuracy: 0.9497 - val_loss: 0.0544 - val_accuracy: 0.9948\n",
      "Epoch 19/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1873 - accuracy: 0.9503 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1801 - accuracy: 0.9525 - val_loss: 0.0508 - val_accuracy: 0.9974\n",
      "Epoch 21/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1722 - accuracy: 0.9546 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "83538/83538 [==============================] - 14s 171us/step - loss: 0.1647 - accuracy: 0.9577 - val_loss: 0.0412 - val_accuracy: 0.9987\n",
      "Epoch 23/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1565 - accuracy: 0.9592 - val_loss: 0.0392 - val_accuracy: 0.9987\n",
      "Epoch 24/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1529 - accuracy: 0.9602 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "83538/83538 [==============================] - 14s 172us/step - loss: 0.1440 - accuracy: 0.9625 - val_loss: 0.0393 - val_accuracy: 0.9987\n",
      "Train on 83538 samples, validate on 767 samples\n",
      "Epoch 1/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 1.6098 - accuracy: 0.5349 - val_loss: 0.6532 - val_accuracy: 0.9048\n",
      "Epoch 2/150\n",
      "83538/83538 [==============================] - 15s 177us/step - loss: 0.9455 - accuracy: 0.7503 - val_loss: 0.3833 - val_accuracy: 0.9596\n",
      "Epoch 3/150\n",
      "83538/83538 [==============================] - 15s 176us/step - loss: 0.7336 - accuracy: 0.8134 - val_loss: 0.2781 - val_accuracy: 0.9726\n",
      "Epoch 4/150\n",
      "83538/83538 [==============================] - 16s 187us/step - loss: 0.6085 - accuracy: 0.8476 - val_loss: 0.2552 - val_accuracy: 0.9674\n",
      "Epoch 5/150\n",
      "83538/83538 [==============================] - 16s 192us/step - loss: 0.5235 - accuracy: 0.8684 - val_loss: 0.2102 - val_accuracy: 0.9713\n",
      "Epoch 6/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 0.4603 - accuracy: 0.8835 - val_loss: 0.1653 - val_accuracy: 0.9870\n",
      "Epoch 7/150\n",
      "83538/83538 [==============================] - 16s 190us/step - loss: 0.4096 - accuracy: 0.8962 - val_loss: 0.1602 - val_accuracy: 0.9778\n",
      "Epoch 8/150\n",
      "83538/83538 [==============================] - 16s 187us/step - loss: 0.3716 - accuracy: 0.9044 - val_loss: 0.2164 - val_accuracy: 0.9544\n",
      "Epoch 9/150\n",
      "83538/83538 [==============================] - 16s 189us/step - loss: 0.3386 - accuracy: 0.9123 - val_loss: 0.1492 - val_accuracy: 0.9739\n",
      "Epoch 10/150\n",
      "83538/83538 [==============================] - 16s 190us/step - loss: 0.3116 - accuracy: 0.9189 - val_loss: 0.1228 - val_accuracy: 0.9778\n",
      "Epoch 11/150\n",
      "83538/83538 [==============================] - 16s 188us/step - loss: 0.2886 - accuracy: 0.9242 - val_loss: 0.1229 - val_accuracy: 0.9765\n",
      "Epoch 12/150\n",
      "83538/83538 [==============================] - 16s 190us/step - loss: 0.2677 - accuracy: 0.9305 - val_loss: 0.1150 - val_accuracy: 0.9791\n",
      "Epoch 13/150\n",
      "83538/83538 [==============================] - 16s 189us/step - loss: 0.2519 - accuracy: 0.9342 - val_loss: 0.1480 - val_accuracy: 0.9622\n",
      "Epoch 14/150\n",
      "83538/83538 [==============================] - 15s 185us/step - loss: 0.2353 - accuracy: 0.9391 - val_loss: 0.1178 - val_accuracy: 0.9817\n",
      "Epoch 15/150\n",
      "83538/83538 [==============================] - 15s 184us/step - loss: 0.2226 - accuracy: 0.9419 - val_loss: 0.1090 - val_accuracy: 0.9752\n",
      "Epoch 16/150\n",
      "83538/83538 [==============================] - 15s 185us/step - loss: 0.2104 - accuracy: 0.9447 - val_loss: 0.1386 - val_accuracy: 0.9687\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speeds):\n",
    "    data_set = dir_temp + rf\"/{i}\"\n",
    "    X_train = open_obj(data_set + r\"/X_train\") \n",
    "    y_train = open_obj(data_set + r\"/y_train\")  \n",
    "    X_val = open_obj(data_set + r\"/X_val\")\n",
    "    y_val = open_obj(data_set + r\"/y_val\")\n",
    "\n",
    "    X_train, y_train = augment(X_train, y_train)   # augmented\n",
    "\n",
    "    X_train = np.expand_dims(X_train[:,:n_features], axis=2)\n",
    "    X_val = np.expand_dims(X_val[:,:n_features], axis=2)\n",
    "\n",
    "    dir_model = dir_data + rf\"/models/vibration_augmented/{i}\"\n",
    "    os.makedirs(dir_model)\n",
    "    cp = callbacks.ModelCheckpoint(dir_model + r\"/model_{epoch:02d}_{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    define_model(X_train, y_train, X_val, y_val, es, cp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec9934d05f2433ac775bd4943a80c56f88370a8daa9f676a715cc5a3d6479729"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tactip': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
