{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prediction models for texture \n",
    "* convolutional neural network and LSTM over samples; input features_SA and features RA of size (n_pins, n_pins, n_samples) representing firing rate over time on an n_pins x n_pins square array                \n",
    "* training data concatenated over speed leaving one speed out but retained for testing\n",
    "* therefore total of n_speed models (here 10), one per speed\n",
    "* i.e. prediction of texture independent of held-out speed\n",
    "\n",
    "To run, first edit dir_data to path where data is stored; spaital/process_static in this directory should be run first.\n",
    "\n",
    "Because of the large amount of data, a temporary folder is used for the training data, so it can be deleted after training the dynamic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def open_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = os.environ[\"DATAPATH\"] + r\"/open/afferents-tactile-textures-jrsi2022\"\n",
    "dir_temp = os.environ[\"TEMPPATH\"] + r\"/dynamic\"\n",
    "\n",
    "n_frames = 10\n",
    "n_speeds = 10\n",
    "n_textures = 13\n",
    "n_pins = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session\n",
    "from keras import optimizers, regularizers, callbacks, Input, Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, LSTM, TimeDistributed\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(X_train, y_train, X_val, y_val, es, cp):\n",
    "    \n",
    "    clear_session()\n",
    "    \n",
    "    config = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)) # device_count = {'GPU': 1}\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    set_session(session)\n",
    "    \n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    \n",
    "    cnn = Sequential()\n",
    "    cnn.add(Conv2D(64, (3,3), activation='relu', padding = \"same\", input_shape=(n_pins,n_pins,1)))\n",
    "    cnn.add(MaxPooling2D((2,2)))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(Conv2D(128, (3,3), activation='relu', padding = \"same\"))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(Conv2D(128, (3,3), activation='relu', padding = \"valid\"))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(MaxPooling2D((2,2)))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    rnn = Sequential()\n",
    "    rnn.add(LSTM(n_frames, return_sequences = True))\n",
    "    rnn.add(LSTM(n_frames, return_sequences = True))\n",
    "    rnn.add(LSTM(n_frames))\n",
    "\n",
    "    dense = Sequential()\n",
    "    dense.add(Dropout(0.4))\n",
    "    dense.add(Dense(32, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "    dense.add(BatchNormalization())\n",
    "    dense.add(Dropout(0.2))\n",
    "    dense.add(Dense(16, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "    dense.add(BatchNormalization())\n",
    "    dense.add(Dropout(0.2))\n",
    "    dense.add(Dense(n_textures, kernel_regularizer=regularizers.l2(0.005), activation='softmax'))\n",
    "\n",
    "    main_input = Input(shape=(n_frames, n_pins, n_pins, 1))\n",
    "\n",
    "    model = TimeDistributed(cnn)(main_input) \n",
    "    model = rnn(model)\n",
    "    model = dense(model) \n",
    "\n",
    "    final_model = Model(inputs=main_input, outputs=model)\n",
    "    final_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])\n",
    "    final_model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=150, batch_size=64, shuffle=True, callbacks=[es,cp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# leave-one-speed-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nl13426\\anaconda3\\envs\\tactip\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 2.4744 - accuracy: 0.2589 - val_loss: 2.4514 - val_accuracy: 0.2711\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 1.6706 - accuracy: 0.5358 - val_loss: 2.4614 - val_accuracy: 0.2978\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 1.3046 - accuracy: 0.6831 - val_loss: 2.5428 - val_accuracy: 0.3271\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 1.0743 - accuracy: 0.7706 - val_loss: 2.6159 - val_accuracy: 0.3172\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.9058 - accuracy: 0.8239 - val_loss: 2.6536 - val_accuracy: 0.3394\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.7934 - accuracy: 0.8516 - val_loss: 2.6652 - val_accuracy: 0.3646\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.7060 - accuracy: 0.8745 - val_loss: 2.9647 - val_accuracy: 0.3428\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.6409 - accuracy: 0.8880 - val_loss: 2.8092 - val_accuracy: 0.3720\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.5951 - accuracy: 0.8989 - val_loss: 3.0662 - val_accuracy: 0.3240\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.5529 - accuracy: 0.9079 - val_loss: 3.0504 - val_accuracy: 0.3695\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.5179 - accuracy: 0.9166 - val_loss: 3.3828 - val_accuracy: 0.3388\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.4818 - accuracy: 0.9253 - val_loss: 3.5188 - val_accuracy: 0.3492\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.4801 - accuracy: 0.9221 - val_loss: 3.5595 - val_accuracy: 0.3523\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 920us/step - loss: 0.4421 - accuracy: 0.9313 - val_loss: 3.6627 - val_accuracy: 0.3258\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.4192 - accuracy: 0.9386 - val_loss: 3.5056 - val_accuracy: 0.3572\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.4015 - accuracy: 0.9399 - val_loss: 3.8111 - val_accuracy: 0.3400\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3845 - accuracy: 0.9431 - val_loss: 3.6008 - val_accuracy: 0.3532\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.4036 - accuracy: 0.9352 - val_loss: 3.6362 - val_accuracy: 0.3705\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3624 - accuracy: 0.9452 - val_loss: 3.6443 - val_accuracy: 0.3575\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.3454 - accuracy: 0.9497 - val_loss: 3.4353 - val_accuracy: 0.4095\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.3328 - accuracy: 0.9516 - val_loss: 3.9032 - val_accuracy: 0.3652\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3188 - accuracy: 0.9539 - val_loss: 3.9628 - val_accuracy: 0.3520\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3118 - accuracy: 0.9551 - val_loss: 4.1229 - val_accuracy: 0.3160\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3245 - accuracy: 0.9501 - val_loss: 4.1092 - val_accuracy: 0.3178\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2960 - accuracy: 0.9569 - val_loss: 4.0774 - val_accuracy: 0.3166\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2857 - accuracy: 0.9594 - val_loss: 4.1266 - val_accuracy: 0.3397\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2813 - accuracy: 0.9584 - val_loss: 4.0260 - val_accuracy: 0.3329\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.2762 - accuracy: 0.9586 - val_loss: 4.0243 - val_accuracy: 0.3492\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2759 - accuracy: 0.9592 - val_loss: 4.1059 - val_accuracy: 0.3329\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2726 - accuracy: 0.9595 - val_loss: 4.0481 - val_accuracy: 0.3375\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2581 - accuracy: 0.9621 - val_loss: 4.0569 - val_accuracy: 0.3335\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2496 - accuracy: 0.9626 - val_loss: 4.1189 - val_accuracy: 0.3418\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2610 - accuracy: 0.9582 - val_loss: 4.1209 - val_accuracy: 0.3428\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2431 - accuracy: 0.9626 - val_loss: 4.7966 - val_accuracy: 0.2742\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2395 - accuracy: 0.9639 - val_loss: 4.3732 - val_accuracy: 0.3286\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2314 - accuracy: 0.9652 - val_loss: 4.4022 - val_accuracy: 0.3314\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2302 - accuracy: 0.9646 - val_loss: 4.0451 - val_accuracy: 0.3778\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2265 - accuracy: 0.9648 - val_loss: 4.3383 - val_accuracy: 0.3406\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2220 - accuracy: 0.9660 - val_loss: 3.9879 - val_accuracy: 0.3763\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 54s 932us/step - loss: 0.2445 - accuracy: 0.9602 - val_loss: 4.2175 - val_accuracy: 0.3443\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 2.5354 - accuracy: 0.2308 - val_loss: 2.5076 - val_accuracy: 0.2634\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 939us/step - loss: 1.7808 - accuracy: 0.4743 - val_loss: 2.4141 - val_accuracy: 0.2935\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 1.3875 - accuracy: 0.6442 - val_loss: 2.2299 - val_accuracy: 0.3489\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 1.1304 - accuracy: 0.7494 - val_loss: 2.3543 - val_accuracy: 0.3200\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.9477 - accuracy: 0.8114 - val_loss: 2.3375 - val_accuracy: 0.3511\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.8269 - accuracy: 0.8434 - val_loss: 2.4156 - val_accuracy: 0.3622\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.7302 - accuracy: 0.8667 - val_loss: 2.4608 - val_accuracy: 0.3692\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.6557 - accuracy: 0.8858 - val_loss: 2.7986 - val_accuracy: 0.3815\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 55s 938us/step - loss: 0.6071 - accuracy: 0.8958 - val_loss: 2.7602 - val_accuracy: 0.3945\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.5610 - accuracy: 0.9054 - val_loss: 3.0776 - val_accuracy: 0.3862\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.5260 - accuracy: 0.9132 - val_loss: 2.9353 - val_accuracy: 0.4046\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.4940 - accuracy: 0.9204 - val_loss: 3.1755 - val_accuracy: 0.3994\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.4758 - accuracy: 0.9225 - val_loss: 3.3974 - val_accuracy: 0.3683\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.4553 - accuracy: 0.9253 - val_loss: 3.4394 - val_accuracy: 0.3914\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.4362 - accuracy: 0.9303 - val_loss: 3.4577 - val_accuracy: 0.4034\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.4319 - accuracy: 0.9292 - val_loss: 3.3863 - val_accuracy: 0.3588\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.4013 - accuracy: 0.9371 - val_loss: 3.2670 - val_accuracy: 0.4154\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.3836 - accuracy: 0.9391 - val_loss: 3.4743 - val_accuracy: 0.3886\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3701 - accuracy: 0.9427 - val_loss: 3.4219 - val_accuracy: 0.3877\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3619 - accuracy: 0.9422 - val_loss: 3.5376 - val_accuracy: 0.3957\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3391 - accuracy: 0.9485 - val_loss: 3.5349 - val_accuracy: 0.4022\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3411 - accuracy: 0.9465 - val_loss: 3.9009 - val_accuracy: 0.3668\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3209 - accuracy: 0.9510 - val_loss: 3.5303 - val_accuracy: 0.4132\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3160 - accuracy: 0.9508 - val_loss: 3.6807 - val_accuracy: 0.4003\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3172 - accuracy: 0.9514 - val_loss: 3.5643 - val_accuracy: 0.4206\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2975 - accuracy: 0.9544 - val_loss: 3.8785 - val_accuracy: 0.3822\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2867 - accuracy: 0.9563 - val_loss: 3.3696 - val_accuracy: 0.4237\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2845 - accuracy: 0.9562 - val_loss: 3.7812 - val_accuracy: 0.3942\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2769 - accuracy: 0.9575 - val_loss: 3.7334 - val_accuracy: 0.3957\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2730 - accuracy: 0.9581 - val_loss: 4.0052 - val_accuracy: 0.3926\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2626 - accuracy: 0.9591 - val_loss: 3.9022 - val_accuracy: 0.3837\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 55s 937us/step - loss: 0.2625 - accuracy: 0.9597 - val_loss: 3.5835 - val_accuracy: 0.3997\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2518 - accuracy: 0.9604 - val_loss: 3.7642 - val_accuracy: 0.3945\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2498 - accuracy: 0.9600 - val_loss: 3.7400 - val_accuracy: 0.3932\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2394 - accuracy: 0.9634 - val_loss: 4.1778 - val_accuracy: 0.3683\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2374 - accuracy: 0.9627 - val_loss: 3.9146 - val_accuracy: 0.3957\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2667 - accuracy: 0.9589 - val_loss: 4.4436 - val_accuracy: 0.3738\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2721 - accuracy: 0.9561 - val_loss: 4.3598 - val_accuracy: 0.3606\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2260 - accuracy: 0.9643 - val_loss: 4.1527 - val_accuracy: 0.3865\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2195 - accuracy: 0.9660 - val_loss: 4.3456 - val_accuracy: 0.3560\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2185 - accuracy: 0.9651 - val_loss: 3.9775 - val_accuracy: 0.3600\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2123 - accuracy: 0.9660 - val_loss: 4.4368 - val_accuracy: 0.3714\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2093 - accuracy: 0.9677 - val_loss: 4.5412 - val_accuracy: 0.3818\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2161 - accuracy: 0.9653 - val_loss: 4.3883 - val_accuracy: 0.3763\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2055 - accuracy: 0.9670 - val_loss: 4.1629 - val_accuracy: 0.3985\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.2059 - accuracy: 0.9661 - val_loss: 4.2152 - val_accuracy: 0.3969\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.1987 - accuracy: 0.9685 - val_loss: 4.4254 - val_accuracy: 0.3606\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 2.5220 - accuracy: 0.2378 - val_loss: 2.6350 - val_accuracy: 0.2062\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 1.7393 - accuracy: 0.4994 - val_loss: 2.5464 - val_accuracy: 0.2637\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 1.3412 - accuracy: 0.6625 - val_loss: 2.6887 - val_accuracy: 0.2735\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 1.1067 - accuracy: 0.7504 - val_loss: 2.7213 - val_accuracy: 0.3135\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.9479 - accuracy: 0.8044 - val_loss: 2.9339 - val_accuracy: 0.2640\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.8324 - accuracy: 0.8394 - val_loss: 2.7586 - val_accuracy: 0.3415\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.7334 - accuracy: 0.8657 - val_loss: 3.1749 - val_accuracy: 0.2726\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 932us/step - loss: 0.6795 - accuracy: 0.8736 - val_loss: 3.2451 - val_accuracy: 0.2708\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.6223 - accuracy: 0.8900 - val_loss: 2.9266 - val_accuracy: 0.3289\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.5780 - accuracy: 0.8995 - val_loss: 3.3583 - val_accuracy: 0.2855\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.5328 - accuracy: 0.9097 - val_loss: 3.4818 - val_accuracy: 0.3148\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.5066 - accuracy: 0.9164 - val_loss: 3.8943 - val_accuracy: 0.2425\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.4809 - accuracy: 0.9219 - val_loss: 3.4659 - val_accuracy: 0.3240\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.4707 - accuracy: 0.9216 - val_loss: 3.9870 - val_accuracy: 0.2914\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.4386 - accuracy: 0.9294 - val_loss: 3.7828 - val_accuracy: 0.3089\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.4231 - accuracy: 0.9320 - val_loss: 4.0225 - val_accuracy: 0.2588\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.3983 - accuracy: 0.9388 - val_loss: 4.0830 - val_accuracy: 0.3302\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.3869 - accuracy: 0.9399 - val_loss: 4.0890 - val_accuracy: 0.2942\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.3780 - accuracy: 0.9400 - val_loss: 4.3427 - val_accuracy: 0.2775\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3581 - accuracy: 0.9440 - val_loss: 4.5647 - val_accuracy: 0.2622\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3460 - accuracy: 0.9460 - val_loss: 4.6790 - val_accuracy: 0.2631\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3344 - accuracy: 0.9484 - val_loss: 4.4594 - val_accuracy: 0.2705\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3261 - accuracy: 0.9506 - val_loss: 4.6471 - val_accuracy: 0.2920\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3179 - accuracy: 0.9503 - val_loss: 4.5608 - val_accuracy: 0.2822\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3127 - accuracy: 0.9497 - val_loss: 4.2993 - val_accuracy: 0.2978\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2999 - accuracy: 0.9536 - val_loss: 4.4538 - val_accuracy: 0.3083\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 959us/step - loss: 2.5105 - accuracy: 0.2421 - val_loss: 2.5898 - val_accuracy: 0.1745\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 1.7931 - accuracy: 0.4790 - val_loss: 2.3813 - val_accuracy: 0.3194\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 1.3923 - accuracy: 0.6502 - val_loss: 2.6379 - val_accuracy: 0.1997\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 1.1365 - accuracy: 0.7501 - val_loss: 2.2733 - val_accuracy: 0.3018\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.9589 - accuracy: 0.8051 - val_loss: 2.2401 - val_accuracy: 0.3585\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.8287 - accuracy: 0.8398 - val_loss: 2.5224 - val_accuracy: 0.3135\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.7333 - accuracy: 0.8630 - val_loss: 2.3616 - val_accuracy: 0.4025\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.6582 - accuracy: 0.8838 - val_loss: 2.7103 - val_accuracy: 0.3763\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.6029 - accuracy: 0.8967 - val_loss: 2.9456 - val_accuracy: 0.3157\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.5595 - accuracy: 0.9058 - val_loss: 2.6441 - val_accuracy: 0.3760\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.5244 - accuracy: 0.9134 - val_loss: 2.9728 - val_accuracy: 0.3268\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.5040 - accuracy: 0.9173 - val_loss: 2.9740 - val_accuracy: 0.3594\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4725 - accuracy: 0.9238 - val_loss: 3.3188 - val_accuracy: 0.3040\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4432 - accuracy: 0.9310 - val_loss: 3.5254 - val_accuracy: 0.2960\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4334 - accuracy: 0.9321 - val_loss: 3.5503 - val_accuracy: 0.3175\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4014 - accuracy: 0.9400 - val_loss: 3.7889 - val_accuracy: 0.3003\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3817 - accuracy: 0.9441 - val_loss: 3.4771 - val_accuracy: 0.3105\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3735 - accuracy: 0.9429 - val_loss: 3.7000 - val_accuracy: 0.3160\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3618 - accuracy: 0.9449 - val_loss: 3.9210 - val_accuracy: 0.3000\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3435 - accuracy: 0.9505 - val_loss: 3.8451 - val_accuracy: 0.2898\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3291 - accuracy: 0.9514 - val_loss: 4.1033 - val_accuracy: 0.2905\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3393 - accuracy: 0.9483 - val_loss: 3.9409 - val_accuracy: 0.3188\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3158 - accuracy: 0.9538 - val_loss: 4.2723 - val_accuracy: 0.3065\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.3042 - accuracy: 0.9556 - val_loss: 4.4505 - val_accuracy: 0.3169\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.2929 - accuracy: 0.9570 - val_loss: 4.1982 - val_accuracy: 0.3262\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.2833 - accuracy: 0.9585 - val_loss: 4.0989 - val_accuracy: 0.3360\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.2774 - accuracy: 0.9591 - val_loss: 4.1962 - val_accuracy: 0.3298\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 2.5662 - accuracy: 0.2295 - val_loss: 2.4354 - val_accuracy: 0.2508\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 1.7691 - accuracy: 0.4964 - val_loss: 2.0615 - val_accuracy: 0.3957\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 1.3431 - accuracy: 0.6783 - val_loss: 2.2205 - val_accuracy: 0.3609\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 1.0915 - accuracy: 0.7658 - val_loss: 2.2126 - val_accuracy: 0.3895\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.9254 - accuracy: 0.8177 - val_loss: 2.3665 - val_accuracy: 0.3791\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.8100 - accuracy: 0.8462 - val_loss: 2.2639 - val_accuracy: 0.4095\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.7414 - accuracy: 0.8590 - val_loss: 2.0509 - val_accuracy: 0.4554\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.6532 - accuracy: 0.8854 - val_loss: 2.4181 - val_accuracy: 0.4542\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.6115 - accuracy: 0.8930 - val_loss: 2.2789 - val_accuracy: 0.4723\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.5684 - accuracy: 0.9027 - val_loss: 2.4946 - val_accuracy: 0.4335\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.5363 - accuracy: 0.9091 - val_loss: 2.8982 - val_accuracy: 0.4126\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.5060 - accuracy: 0.9161 - val_loss: 2.6269 - val_accuracy: 0.4320\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.4919 - accuracy: 0.9161 - val_loss: 2.8054 - val_accuracy: 0.4289\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.4581 - accuracy: 0.9259 - val_loss: 3.0413 - val_accuracy: 0.4022\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.4427 - accuracy: 0.9282 - val_loss: 2.9867 - val_accuracy: 0.4609\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 54s 921us/step - loss: 0.4247 - accuracy: 0.9316 - val_loss: 2.8408 - val_accuracy: 0.4563\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.4064 - accuracy: 0.9349 - val_loss: 3.1203 - val_accuracy: 0.4055\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 54s 920us/step - loss: 0.4042 - accuracy: 0.9354 - val_loss: 2.9110 - val_accuracy: 0.4348\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.3848 - accuracy: 0.9395 - val_loss: 3.0329 - val_accuracy: 0.4465\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3633 - accuracy: 0.9449 - val_loss: 2.9757 - val_accuracy: 0.4794\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.3470 - accuracy: 0.9470 - val_loss: 3.3966 - val_accuracy: 0.4505\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3414 - accuracy: 0.9476 - val_loss: 2.9082 - val_accuracy: 0.4788\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.3390 - accuracy: 0.9471 - val_loss: 3.3060 - val_accuracy: 0.4135\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3236 - accuracy: 0.9494 - val_loss: 2.9030 - val_accuracy: 0.4815\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3183 - accuracy: 0.9501 - val_loss: 3.1393 - val_accuracy: 0.4138\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.3028 - accuracy: 0.9537 - val_loss: 2.8600 - val_accuracy: 0.4348\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.2964 - accuracy: 0.9544 - val_loss: 3.2641 - val_accuracy: 0.4698\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 54s 920us/step - loss: 0.2956 - accuracy: 0.9514 - val_loss: 3.5171 - val_accuracy: 0.4098\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 54s 920us/step - loss: 0.2819 - accuracy: 0.9564 - val_loss: 3.2574 - val_accuracy: 0.4320\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 54s 919us/step - loss: 0.2701 - accuracy: 0.9577 - val_loss: 3.2471 - val_accuracy: 0.4369\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 55s 937us/step - loss: 0.2736 - accuracy: 0.9575 - val_loss: 3.4519 - val_accuracy: 0.4354\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 982us/step - loss: 0.2819 - accuracy: 0.9548 - val_loss: 3.5373 - val_accuracy: 0.4157\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 55s 946us/step - loss: 0.2570 - accuracy: 0.9611 - val_loss: 3.5546 - val_accuracy: 0.4532\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2523 - accuracy: 0.9605 - val_loss: 3.4872 - val_accuracy: 0.4098\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.2435 - accuracy: 0.9625 - val_loss: 3.3087 - val_accuracy: 0.4683\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.2377 - accuracy: 0.9635 - val_loss: 3.5528 - val_accuracy: 0.4369\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.2379 - accuracy: 0.9636 - val_loss: 3.5708 - val_accuracy: 0.4585\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2535 - accuracy: 0.9593 - val_loss: 3.6421 - val_accuracy: 0.4222\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 55s 944us/step - loss: 0.2302 - accuracy: 0.9641 - val_loss: 3.5480 - val_accuracy: 0.4440\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2234 - accuracy: 0.9652 - val_loss: 3.5005 - val_accuracy: 0.4554\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2207 - accuracy: 0.9667 - val_loss: 3.1557 - val_accuracy: 0.4692\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2282 - accuracy: 0.9640 - val_loss: 3.1607 - val_accuracy: 0.4735\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 55s 943us/step - loss: 0.2126 - accuracy: 0.9670 - val_loss: 3.2860 - val_accuracy: 0.4745\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2136 - accuracy: 0.9661 - val_loss: 3.6589 - val_accuracy: 0.4215\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 2.5661 - accuracy: 0.2271 - val_loss: 2.5655 - val_accuracy: 0.2665\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 938us/step - loss: 1.7878 - accuracy: 0.4897 - val_loss: 2.3532 - val_accuracy: 0.3554\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 1.3684 - accuracy: 0.6616 - val_loss: 2.4663 - val_accuracy: 0.3800\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 1.1214 - accuracy: 0.7545 - val_loss: 2.4119 - val_accuracy: 0.3855\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.9465 - accuracy: 0.8066 - val_loss: 2.4917 - val_accuracy: 0.4080\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.8317 - accuracy: 0.8383 - val_loss: 2.8844 - val_accuracy: 0.3249\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.7229 - accuracy: 0.8691 - val_loss: 2.9512 - val_accuracy: 0.3548\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.6671 - accuracy: 0.8815 - val_loss: 2.6890 - val_accuracy: 0.4231\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.6093 - accuracy: 0.8946 - val_loss: 3.0132 - val_accuracy: 0.3674\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.5647 - accuracy: 0.9046 - val_loss: 3.4519 - val_accuracy: 0.3560\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.5263 - accuracy: 0.9143 - val_loss: 3.5745 - val_accuracy: 0.3443\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.5075 - accuracy: 0.9171 - val_loss: 3.5593 - val_accuracy: 0.3517\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.4801 - accuracy: 0.9221 - val_loss: 3.4826 - val_accuracy: 0.3788\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.4494 - accuracy: 0.9286 - val_loss: 3.9266 - val_accuracy: 0.3338\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.4412 - accuracy: 0.9289 - val_loss: 3.8022 - val_accuracy: 0.3831\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.4127 - accuracy: 0.9360 - val_loss: 3.7453 - val_accuracy: 0.4046\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3936 - accuracy: 0.9388 - val_loss: 4.0057 - val_accuracy: 0.3686\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.3842 - accuracy: 0.9394 - val_loss: 4.3351 - val_accuracy: 0.3477\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3663 - accuracy: 0.9426 - val_loss: 4.1779 - val_accuracy: 0.4012\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3577 - accuracy: 0.9443 - val_loss: 4.3597 - val_accuracy: 0.3591\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3421 - accuracy: 0.9476 - val_loss: 4.5462 - val_accuracy: 0.3625\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3291 - accuracy: 0.9503 - val_loss: 4.2380 - val_accuracy: 0.3477\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.3199 - accuracy: 0.9502 - val_loss: 4.4637 - val_accuracy: 0.3431\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.3151 - accuracy: 0.9515 - val_loss: 4.5224 - val_accuracy: 0.3557\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.2994 - accuracy: 0.9550 - val_loss: 4.8989 - val_accuracy: 0.3129\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.2936 - accuracy: 0.9553 - val_loss: 4.6419 - val_accuracy: 0.3517\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 54s 932us/step - loss: 0.2857 - accuracy: 0.9565 - val_loss: 4.8803 - val_accuracy: 0.3551\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2782 - accuracy: 0.9577 - val_loss: 4.7532 - val_accuracy: 0.3560\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 956us/step - loss: 2.5435 - accuracy: 0.2362 - val_loss: 2.5110 - val_accuracy: 0.2566\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 1.7760 - accuracy: 0.4855 - val_loss: 2.4685 - val_accuracy: 0.2871\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 1.3751 - accuracy: 0.6528 - val_loss: 2.5258 - val_accuracy: 0.2865\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 1.1161 - accuracy: 0.7534 - val_loss: 2.8071 - val_accuracy: 0.2846\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 1.0081 - accuracy: 0.7823 - val_loss: 2.6215 - val_accuracy: 0.3191\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.8283 - accuracy: 0.8406 - val_loss: 2.9613 - val_accuracy: 0.3249\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.7302 - accuracy: 0.8650 - val_loss: 2.9651 - val_accuracy: 0.3129\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.6622 - accuracy: 0.8804 - val_loss: 3.0113 - val_accuracy: 0.3603\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.6132 - accuracy: 0.8911 - val_loss: 3.6582 - val_accuracy: 0.3200\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.5677 - accuracy: 0.9017 - val_loss: 3.5988 - val_accuracy: 0.3123\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.5266 - accuracy: 0.9121 - val_loss: 4.1081 - val_accuracy: 0.2822\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.5165 - accuracy: 0.9116 - val_loss: 3.4935 - val_accuracy: 0.3071\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.4772 - accuracy: 0.9222 - val_loss: 3.5238 - val_accuracy: 0.3151\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.4494 - accuracy: 0.9275 - val_loss: 3.7108 - val_accuracy: 0.3012\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.4312 - accuracy: 0.9314 - val_loss: 4.0506 - val_accuracy: 0.3071\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.4193 - accuracy: 0.9319 - val_loss: 4.1405 - val_accuracy: 0.3068\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3897 - accuracy: 0.9419 - val_loss: 3.8559 - val_accuracy: 0.3114\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.3811 - accuracy: 0.9398 - val_loss: 3.8284 - val_accuracy: 0.3258\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.3756 - accuracy: 0.9418 - val_loss: 3.6617 - val_accuracy: 0.3920\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.3536 - accuracy: 0.9458 - val_loss: 4.0796 - val_accuracy: 0.3243\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3354 - accuracy: 0.9506 - val_loss: 4.0872 - val_accuracy: 0.3335\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.3266 - accuracy: 0.9516 - val_loss: 4.2260 - val_accuracy: 0.3532\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.3257 - accuracy: 0.9510 - val_loss: 4.1912 - val_accuracy: 0.3397\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.3095 - accuracy: 0.9531 - val_loss: 4.0981 - val_accuracy: 0.3305\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.3070 - accuracy: 0.9539 - val_loss: 4.1499 - val_accuracy: 0.3308\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2914 - accuracy: 0.9562 - val_loss: 4.1802 - val_accuracy: 0.3480\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.2815 - accuracy: 0.9581 - val_loss: 4.5825 - val_accuracy: 0.3369\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.3058 - accuracy: 0.9520 - val_loss: 4.2906 - val_accuracy: 0.3551\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.2699 - accuracy: 0.9592 - val_loss: 4.1695 - val_accuracy: 0.3834\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.2619 - accuracy: 0.9611 - val_loss: 4.2524 - val_accuracy: 0.3578\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.2682 - accuracy: 0.9586 - val_loss: 4.2833 - val_accuracy: 0.3748\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.2559 - accuracy: 0.9606 - val_loss: 4.3991 - val_accuracy: 0.3692\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2491 - accuracy: 0.9629 - val_loss: 4.5061 - val_accuracy: 0.3554\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.2528 - accuracy: 0.9612 - val_loss: 4.2316 - val_accuracy: 0.3705\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2385 - accuracy: 0.9640 - val_loss: 4.5294 - val_accuracy: 0.3422\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.2372 - accuracy: 0.9635 - val_loss: 4.8624 - val_accuracy: 0.2892\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.2339 - accuracy: 0.9636 - val_loss: 4.5884 - val_accuracy: 0.3480\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.2298 - accuracy: 0.9652 - val_loss: 4.7295 - val_accuracy: 0.3732\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.2242 - accuracy: 0.9654 - val_loss: 4.5407 - val_accuracy: 0.3400\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 2.5201 - accuracy: 0.2386 - val_loss: 2.3636 - val_accuracy: 0.2840\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 943us/step - loss: 1.7608 - accuracy: 0.4990 - val_loss: 2.0734 - val_accuracy: 0.4431\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 938us/step - loss: 1.3631 - accuracy: 0.6596 - val_loss: 2.1681 - val_accuracy: 0.4095\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 1.1103 - accuracy: 0.7540 - val_loss: 2.4393 - val_accuracy: 0.2800\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.9525 - accuracy: 0.8030 - val_loss: 2.3268 - val_accuracy: 0.3289\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.8259 - accuracy: 0.8393 - val_loss: 2.1625 - val_accuracy: 0.4609\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.7354 - accuracy: 0.8615 - val_loss: 2.0653 - val_accuracy: 0.4837\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 55s 942us/step - loss: 0.6697 - accuracy: 0.8774 - val_loss: 2.1209 - val_accuracy: 0.4655\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 55s 942us/step - loss: 0.6164 - accuracy: 0.8898 - val_loss: 2.2875 - val_accuracy: 0.4440\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 55s 938us/step - loss: 0.5747 - accuracy: 0.8991 - val_loss: 2.1638 - val_accuracy: 0.4502\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.5380 - accuracy: 0.9065 - val_loss: 2.1654 - val_accuracy: 0.4991\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 55s 940us/step - loss: 0.5086 - accuracy: 0.9143 - val_loss: 2.2344 - val_accuracy: 0.4895\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.4834 - accuracy: 0.9187 - val_loss: 2.3593 - val_accuracy: 0.4754\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.4622 - accuracy: 0.9238 - val_loss: 2.1817 - val_accuracy: 0.5237\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.4416 - accuracy: 0.9278 - val_loss: 2.1821 - val_accuracy: 0.5129\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.4229 - accuracy: 0.9304 - val_loss: 2.2160 - val_accuracy: 0.5357\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.4045 - accuracy: 0.9345 - val_loss: 2.2901 - val_accuracy: 0.5138\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3951 - accuracy: 0.9352 - val_loss: 2.5403 - val_accuracy: 0.4637\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3798 - accuracy: 0.9397 - val_loss: 2.1659 - val_accuracy: 0.5335\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.3630 - accuracy: 0.9424 - val_loss: 2.2620 - val_accuracy: 0.5255\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3525 - accuracy: 0.9442 - val_loss: 2.3256 - val_accuracy: 0.4963\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.3370 - accuracy: 0.9481 - val_loss: 2.3194 - val_accuracy: 0.5055\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3299 - accuracy: 0.9480 - val_loss: 2.3785 - val_accuracy: 0.5289\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.3197 - accuracy: 0.9502 - val_loss: 2.3323 - val_accuracy: 0.5317\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3081 - accuracy: 0.9525 - val_loss: 2.5036 - val_accuracy: 0.5354\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.3050 - accuracy: 0.9532 - val_loss: 2.5711 - val_accuracy: 0.4738\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2924 - accuracy: 0.9557 - val_loss: 2.6050 - val_accuracy: 0.4797\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2961 - accuracy: 0.9534 - val_loss: 2.3764 - val_accuracy: 0.5538\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.2808 - accuracy: 0.9567 - val_loss: 2.2090 - val_accuracy: 0.5422\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2682 - accuracy: 0.9597 - val_loss: 2.7180 - val_accuracy: 0.4658\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2690 - accuracy: 0.9581 - val_loss: 2.5984 - val_accuracy: 0.4975\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2591 - accuracy: 0.9598 - val_loss: 2.3085 - val_accuracy: 0.5662\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.2550 - accuracy: 0.9610 - val_loss: 2.5832 - val_accuracy: 0.5083\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2490 - accuracy: 0.9611 - val_loss: 2.4869 - val_accuracy: 0.5520\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2426 - accuracy: 0.9626 - val_loss: 3.2977 - val_accuracy: 0.4077\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2379 - accuracy: 0.9634 - val_loss: 2.2917 - val_accuracy: 0.5735\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 55s 941us/step - loss: 0.2321 - accuracy: 0.9649 - val_loss: 2.5842 - val_accuracy: 0.5231\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.2284 - accuracy: 0.9652 - val_loss: 2.7907 - val_accuracy: 0.5265\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2253 - accuracy: 0.9654 - val_loss: 2.4163 - val_accuracy: 0.5483\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2282 - accuracy: 0.9648 - val_loss: 2.6894 - val_accuracy: 0.5151\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2184 - accuracy: 0.9664 - val_loss: 3.2481 - val_accuracy: 0.4375\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2131 - accuracy: 0.9674 - val_loss: 2.9658 - val_accuracy: 0.4634\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.2115 - accuracy: 0.9669 - val_loss: 2.6351 - val_accuracy: 0.5434\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2102 - accuracy: 0.9663 - val_loss: 2.8765 - val_accuracy: 0.4671\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 55s 942us/step - loss: 0.2062 - accuracy: 0.9680 - val_loss: 2.9665 - val_accuracy: 0.5225\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 55s 932us/step - loss: 0.2070 - accuracy: 0.9666 - val_loss: 2.9907 - val_accuracy: 0.5102\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.2009 - accuracy: 0.9681 - val_loss: 2.6371 - val_accuracy: 0.5418\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.1981 - accuracy: 0.9692 - val_loss: 2.7067 - val_accuracy: 0.4988\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.1967 - accuracy: 0.9685 - val_loss: 2.9183 - val_accuracy: 0.4988\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 55s 940us/step - loss: 0.1922 - accuracy: 0.9689 - val_loss: 2.5199 - val_accuracy: 0.5683\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.1912 - accuracy: 0.9696 - val_loss: 2.7743 - val_accuracy: 0.5326\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.1894 - accuracy: 0.9698 - val_loss: 2.7458 - val_accuracy: 0.5514\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 55s 944us/step - loss: 0.1850 - accuracy: 0.9702 - val_loss: 3.0619 - val_accuracy: 0.4895\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 55s 937us/step - loss: 0.1826 - accuracy: 0.9706 - val_loss: 2.7998 - val_accuracy: 0.5292\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.1828 - accuracy: 0.9694 - val_loss: 2.7147 - val_accuracy: 0.5535\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.1881 - accuracy: 0.9677 - val_loss: 2.8347 - val_accuracy: 0.5071\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 956us/step - loss: 2.5361 - accuracy: 0.2351 - val_loss: 2.4317 - val_accuracy: 0.2751\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 1.7762 - accuracy: 0.4890 - val_loss: 2.3337 - val_accuracy: 0.3397\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 1.3688 - accuracy: 0.6613 - val_loss: 2.4446 - val_accuracy: 0.3111\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 1.1193 - accuracy: 0.7478 - val_loss: 2.4988 - val_accuracy: 0.3095\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.9440 - accuracy: 0.8049 - val_loss: 2.4878 - val_accuracy: 0.3185\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.8302 - accuracy: 0.8351 - val_loss: 2.5112 - val_accuracy: 0.3342\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 54s 920us/step - loss: 0.7254 - accuracy: 0.8656 - val_loss: 2.2384 - val_accuracy: 0.3865\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.6656 - accuracy: 0.8784 - val_loss: 2.4524 - val_accuracy: 0.3609\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 54s 921us/step - loss: 0.6069 - accuracy: 0.8945 - val_loss: 2.3748 - val_accuracy: 0.4040\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.5753 - accuracy: 0.8962 - val_loss: 2.9541 - val_accuracy: 0.3471\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 921us/step - loss: 0.5319 - accuracy: 0.9091 - val_loss: 2.6093 - val_accuracy: 0.3812\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.5077 - accuracy: 0.9138 - val_loss: 2.8085 - val_accuracy: 0.4055\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.4843 - accuracy: 0.9172 - val_loss: 2.6785 - val_accuracy: 0.4111\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.4495 - accuracy: 0.9266 - val_loss: 2.5581 - val_accuracy: 0.4172\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.4295 - accuracy: 0.9318 - val_loss: 2.7381 - val_accuracy: 0.4388\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.4188 - accuracy: 0.9319 - val_loss: 2.7487 - val_accuracy: 0.4206\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3906 - accuracy: 0.9400 - val_loss: 2.6545 - val_accuracy: 0.4480\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.3846 - accuracy: 0.9380 - val_loss: 2.6765 - val_accuracy: 0.4502\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3763 - accuracy: 0.9391 - val_loss: 2.9227 - val_accuracy: 0.4009\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3512 - accuracy: 0.9460 - val_loss: 3.0040 - val_accuracy: 0.4178\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.3431 - accuracy: 0.9472 - val_loss: 3.1344 - val_accuracy: 0.3849\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 54s 925us/step - loss: 0.3715 - accuracy: 0.9372 - val_loss: 2.9231 - val_accuracy: 0.3889\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.3196 - accuracy: 0.9527 - val_loss: 3.0331 - val_accuracy: 0.3991\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.3130 - accuracy: 0.9516 - val_loss: 2.9327 - val_accuracy: 0.3988\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 54s 921us/step - loss: 0.3031 - accuracy: 0.9538 - val_loss: 3.1299 - val_accuracy: 0.3966\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.2949 - accuracy: 0.9540 - val_loss: 3.1285 - val_accuracy: 0.4409\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2892 - accuracy: 0.9555 - val_loss: 3.2791 - val_accuracy: 0.3631\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2919 - accuracy: 0.9527 - val_loss: 3.0637 - val_accuracy: 0.3858\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2773 - accuracy: 0.9562 - val_loss: 3.4307 - val_accuracy: 0.3855\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2693 - accuracy: 0.9577 - val_loss: 3.2202 - val_accuracy: 0.4237\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.2758 - accuracy: 0.9550 - val_loss: 3.2692 - val_accuracy: 0.3655\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.2582 - accuracy: 0.9595 - val_loss: 3.5171 - val_accuracy: 0.3492\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 54s 923us/step - loss: 0.2555 - accuracy: 0.9591 - val_loss: 3.3417 - val_accuracy: 0.3735\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.2507 - accuracy: 0.9605 - val_loss: 3.5187 - val_accuracy: 0.3034\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.2465 - accuracy: 0.9614 - val_loss: 3.3282 - val_accuracy: 0.4046\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2410 - accuracy: 0.9606 - val_loss: 3.2687 - val_accuracy: 0.3895\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.2368 - accuracy: 0.9617 - val_loss: 3.5985 - val_accuracy: 0.3932\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 54s 922us/step - loss: 0.2279 - accuracy: 0.9643 - val_loss: 3.5627 - val_accuracy: 0.4065\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 2.4842 - accuracy: 0.2574 - val_loss: 2.2165 - val_accuracy: 0.3631\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 55s 938us/step - loss: 1.6878 - accuracy: 0.5332 - val_loss: 2.3601 - val_accuracy: 0.3754\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 55s 937us/step - loss: 1.2999 - accuracy: 0.6876 - val_loss: 2.2726 - val_accuracy: 0.4178\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 55s 942us/step - loss: 1.0736 - accuracy: 0.7676 - val_loss: 2.4537 - val_accuracy: 0.3400\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 55s 936us/step - loss: 0.9143 - accuracy: 0.8174 - val_loss: 2.5349 - val_accuracy: 0.3760\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.8049 - accuracy: 0.8470 - val_loss: 2.5351 - val_accuracy: 0.3692\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.7175 - accuracy: 0.8693 - val_loss: 2.3163 - val_accuracy: 0.4643\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.6579 - accuracy: 0.8811 - val_loss: 2.6611 - val_accuracy: 0.4092\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.6026 - accuracy: 0.8949 - val_loss: 2.7410 - val_accuracy: 0.3972\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.5716 - accuracy: 0.9005 - val_loss: 2.9120 - val_accuracy: 0.4068\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 54s 924us/step - loss: 0.5228 - accuracy: 0.9140 - val_loss: 3.0004 - val_accuracy: 0.4003\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.4949 - accuracy: 0.9203 - val_loss: 3.2864 - val_accuracy: 0.4003\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 54s 926us/step - loss: 0.4743 - accuracy: 0.9233 - val_loss: 2.9972 - val_accuracy: 0.4203\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 55s 933us/step - loss: 0.4457 - accuracy: 0.9294 - val_loss: 3.3684 - val_accuracy: 0.3631\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 54s 931us/step - loss: 0.4340 - accuracy: 0.9316 - val_loss: 3.3041 - val_accuracy: 0.3960\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.4124 - accuracy: 0.9341 - val_loss: 3.5855 - val_accuracy: 0.3858\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 55s 935us/step - loss: 0.3996 - accuracy: 0.9384 - val_loss: 3.3485 - val_accuracy: 0.4185\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 54s 930us/step - loss: 0.3808 - accuracy: 0.9408 - val_loss: 3.5289 - val_accuracy: 0.3978\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.3628 - accuracy: 0.9446 - val_loss: 3.3254 - val_accuracy: 0.4108\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 55s 934us/step - loss: 0.3511 - accuracy: 0.9471 - val_loss: 3.7368 - val_accuracy: 0.3852\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3417 - accuracy: 0.9489 - val_loss: 3.5557 - val_accuracy: 0.3985\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3369 - accuracy: 0.9480 - val_loss: 3.4232 - val_accuracy: 0.4142\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.3172 - accuracy: 0.9524 - val_loss: 3.4624 - val_accuracy: 0.4225\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 54s 928us/step - loss: 0.3147 - accuracy: 0.9518 - val_loss: 3.4764 - val_accuracy: 0.4249\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.3038 - accuracy: 0.9534 - val_loss: 3.5700 - val_accuracy: 0.4397\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 54s 929us/step - loss: 0.2927 - accuracy: 0.9558 - val_loss: 3.5328 - val_accuracy: 0.4385\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 54s 927us/step - loss: 0.2994 - accuracy: 0.9539 - val_loss: 3.7111 - val_accuracy: 0.4218\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speeds):\n",
    "    data_set = dir_temp + rf\"/{i}\"\n",
    "    X_train = open_obj(data_set + r\"/X_train_SA\")\n",
    "    X_val = open_obj(data_set + r\"/X_val_SA\")\n",
    "    y_train = open_obj(data_set + r\"/y_train_SA\")\n",
    "    y_val = open_obj(data_set + r\"/y_val_SA\")\n",
    "    \n",
    "    dir_model = dir_data + rf\"/models/dynamic_SA/{i}\"\n",
    "    os.makedirs(dir_model, exist_ok=True)\n",
    "    cp = callbacks.ModelCheckpoint(dir_model + r\"/model_{epoch:02d}_{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "    define_model(X_train, y_train[1], X_val, y_val[1], es, cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 63s 1ms/step - loss: 2.5954 - accuracy: 0.2158 - val_loss: 2.5357 - val_accuracy: 0.2203\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 2.1575 - accuracy: 0.3455 - val_loss: 2.5127 - val_accuracy: 0.2357\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 1.9174 - accuracy: 0.4255 - val_loss: 2.5300 - val_accuracy: 0.2569\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 1.7281 - accuracy: 0.4945 - val_loss: 2.4946 - val_accuracy: 0.2732\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 1.5690 - accuracy: 0.5474 - val_loss: 2.4538 - val_accuracy: 0.2898\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 1.4341 - accuracy: 0.5904 - val_loss: 2.5118 - val_accuracy: 0.2926\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 1.3237 - accuracy: 0.6239 - val_loss: 2.5854 - val_accuracy: 0.2757\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 1.2345 - accuracy: 0.6514 - val_loss: 2.6407 - val_accuracy: 0.2957\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 1.1546 - accuracy: 0.6738 - val_loss: 2.5372 - val_accuracy: 0.2982\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 1.0885 - accuracy: 0.6943 - val_loss: 2.4805 - val_accuracy: 0.3117\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 1.0218 - accuracy: 0.7140 - val_loss: 2.6578 - val_accuracy: 0.3120\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.9778 - accuracy: 0.7289 - val_loss: 2.8737 - val_accuracy: 0.3022\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.9255 - accuracy: 0.7417 - val_loss: 2.9403 - val_accuracy: 0.3028\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.9100 - accuracy: 0.7457 - val_loss: 2.6883 - val_accuracy: 0.3302\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.8511 - accuracy: 0.7641 - val_loss: 2.9024 - val_accuracy: 0.3077\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.8102 - accuracy: 0.7758 - val_loss: 2.9601 - val_accuracy: 0.3102- ETA: 1s - ETA: 0s - loss: 0.8093 - \n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.7783 - accuracy: 0.7840 - val_loss: 2.8981 - val_accuracy: 0.3326\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.7490 - accuracy: 0.7926 - val_loss: 2.9771 - val_accuracy: 0.3098\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.7168 - accuracy: 0.8026 - val_loss: 3.1470 - val_accuracy: 0.3157\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.6903 - accuracy: 0.8087 - val_loss: 3.2735 - val_accuracy: 0.3215\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.6683 - accuracy: 0.8152 - val_loss: 3.2621 - val_accuracy: 0.3286\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.6428 - accuracy: 0.8235 - val_loss: 3.0485 - val_accuracy: 0.3286\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.6223 - accuracy: 0.8291 - val_loss: 3.2551 - val_accuracy: 0.3354\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.6072 - accuracy: 0.8331 - val_loss: 3.3896 - val_accuracy: 0.3326\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.5802 - accuracy: 0.8413 - val_loss: 3.3425 - val_accuracy: 0.3366\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 62s 1ms/step - loss: 0.5615 - accuracy: 0.8484 - val_loss: 3.5655 - val_accuracy: 0.3154\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.5478 - accuracy: 0.8524 - val_loss: 3.4457 - val_accuracy: 0.3354\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.5375 - accuracy: 0.8557 - val_loss: 3.6237 - val_accuracy: 0.3268\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 61s 1ms/step - loss: 0.5149 - accuracy: 0.8639 - val_loss: 3.7304 - val_accuracy: 0.3271\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 60s 1ms/step - loss: 0.5169 - accuracy: 0.8612 - val_loss: 3.7019 - val_accuracy: 0.3194\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 58s 996us/step - loss: 0.4909 - accuracy: 0.8714 - val_loss: 3.7398 - val_accuracy: 0.3258\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 58s 996us/step - loss: 0.4823 - accuracy: 0.8751 - val_loss: 3.6459 - val_accuracy: 0.3323\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 58s 996us/step - loss: 0.4731 - accuracy: 0.8765 - val_loss: 3.8414 - val_accuracy: 0.3382\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4599 - accuracy: 0.8823 - val_loss: 4.0019 - val_accuracy: 0.3132\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 58s 995us/step - loss: 0.4452 - accuracy: 0.8862 - val_loss: 3.8969 - val_accuracy: 0.3302ss: 0.4 - - ETA: 0s - loss: 0.444\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 58s 998us/step - loss: 0.4406 - accuracy: 0.8862 - val_loss: 4.0664 - val_accuracy: 0.3234\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 58s 998us/step - loss: 0.4246 - accuracy: 0.8941 - val_loss: 3.8515 - val_accuracy: 0.3262\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4221 - accuracy: 0.8937 - val_loss: 4.2056 - val_accuracy: 0.3265\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 0.4112 - accuracy: 0.8984 - val_loss: 4.1789 - val_accuracy: 0.3105\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 58s 995us/step - loss: 0.3984 - accuracy: 0.9018 - val_loss: 4.2970 - val_accuracy: 0.3188\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 58s 986us/step - loss: 0.3898 - accuracy: 0.9042 - val_loss: 4.3667 - val_accuracy: 0.2966\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 58s 985us/step - loss: 0.3833 - accuracy: 0.9070 - val_loss: 4.3438 - val_accuracy: 0.3166\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.3807 - accuracy: 0.9078 - val_loss: 4.3041 - val_accuracy: 0.3135\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 56s 958us/step - loss: 0.3715 - accuracy: 0.9110 - val_loss: 4.3500 - val_accuracy: 0.3095\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 56s 956us/step - loss: 0.3602 - accuracy: 0.9137 - val_loss: 4.3052 - val_accuracy: 0.3182\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 56s 958us/step - loss: 0.3688 - accuracy: 0.9096 - val_loss: 4.3276 - val_accuracy: 0.3320\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 56s 957us/step - loss: 0.3414 - accuracy: 0.9184 - val_loss: 4.4403 - val_accuracy: 0.3197\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 56s 956us/step - loss: 0.3366 - accuracy: 0.9213 - val_loss: 4.3879 - val_accuracy: 0.3369\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 56s 957us/step - loss: 0.3389 - accuracy: 0.9208 - val_loss: 4.4157 - val_accuracy: 0.3148\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 56s 957us/step - loss: 0.3274 - accuracy: 0.9226 - val_loss: 4.4516 - val_accuracy: 0.3175\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 56s 958us/step - loss: 0.3272 - accuracy: 0.9216 - val_loss: 4.7390 - val_accuracy: 0.3071\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 56s 958us/step - loss: 0.3226 - accuracy: 0.9238 - val_loss: 4.7715 - val_accuracy: 0.3058\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 56s 958us/step - loss: 0.3122 - accuracy: 0.9292 - val_loss: 4.9063 - val_accuracy: 0.3025\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 987us/step - loss: 2.6295 - accuracy: 0.2067 - val_loss: 2.3533 - val_accuracy: 0.3043\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 2.1868 - accuracy: 0.3388 - val_loss: 2.1944 - val_accuracy: 0.3240\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 1.9457 - accuracy: 0.4196 - val_loss: 2.0772 - val_accuracy: 0.3748\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.7597 - accuracy: 0.4830 - val_loss: 1.9730 - val_accuracy: 0.3982\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.6168 - accuracy: 0.5268 - val_loss: 1.9106 - val_accuracy: 0.4258\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.4864 - accuracy: 0.5648 - val_loss: 1.8762 - val_accuracy: 0.4422\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 1.3847 - accuracy: 0.5932 - val_loss: 1.7988 - val_accuracy: 0.4628\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.2984 - accuracy: 0.6207 - val_loss: 1.9341 - val_accuracy: 0.4277\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.2267 - accuracy: 0.6405 - val_loss: 1.7699 - val_accuracy: 0.4766\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.1603 - accuracy: 0.6638 - val_loss: 1.7123 - val_accuracy: 0.4935\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.0960 - accuracy: 0.6822 - val_loss: 1.7626 - val_accuracy: 0.4871\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.0419 - accuracy: 0.6980 - val_loss: 1.8669 - val_accuracy: 0.4662\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.9916 - accuracy: 0.7164 - val_loss: 1.8109 - val_accuracy: 0.4760\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.9476 - accuracy: 0.7303 - val_loss: 1.8852 - val_accuracy: 0.4652\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.9028 - accuracy: 0.7424 - val_loss: 1.8339 - val_accuracy: 0.4849\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.8590 - accuracy: 0.7562 - val_loss: 1.9041 - val_accuracy: 0.4818\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.8276 - accuracy: 0.7653 - val_loss: 1.8118 - val_accuracy: 0.5034\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.7916 - accuracy: 0.7750 - val_loss: 1.8430 - val_accuracy: 0.4942\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.7860 - accuracy: 0.7765 - val_loss: 1.8296 - val_accuracy: 0.4997\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.7381 - accuracy: 0.7934 - val_loss: 1.9955 - val_accuracy: 0.4726\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.7123 - accuracy: 0.7995 - val_loss: 1.8672 - val_accuracy: 0.5135\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6866 - accuracy: 0.8070 - val_loss: 1.9960 - val_accuracy: 0.4868\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6649 - accuracy: 0.8126 - val_loss: 1.9797 - val_accuracy: 0.4951\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.6425 - accuracy: 0.8218 - val_loss: 2.0357 - val_accuracy: 0.5043s\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6224 - accuracy: 0.8287 - val_loss: 2.1623 - val_accuracy: 0.4849\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5988 - accuracy: 0.8368 - val_loss: 2.1194 - val_accuracy: 0.4837\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.5866 - accuracy: 0.8386 - val_loss: 2.1065 - val_accuracy: 0.5006\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5690 - accuracy: 0.8455 - val_loss: 2.1664 - val_accuracy: 0.4914\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.5527 - accuracy: 0.8495 - val_loss: 2.2582 - val_accuracy: 0.4806\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.5440 - accuracy: 0.8539 - val_loss: 2.3317 - val_accuracy: 0.4902\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.5245 - accuracy: 0.8583 - val_loss: 2.3116 - val_accuracy: 0.4963\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5164 - accuracy: 0.8616 - val_loss: 2.3950 - val_accuracy: 0.4720\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.5013 - accuracy: 0.8684 - val_loss: 2.3106 - val_accuracy: 0.4834\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4904 - accuracy: 0.8698 - val_loss: 2.4676 - val_accuracy: 0.4871\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.4765 - accuracy: 0.8750 - val_loss: 2.5181 - val_accuracy: 0.4785\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4808 - accuracy: 0.8746 - val_loss: 2.3355 - val_accuracy: 0.4960\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.4575 - accuracy: 0.8808 - val_loss: 2.3432 - val_accuracy: 0.5012\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4579 - accuracy: 0.8802 - val_loss: 2.3996 - val_accuracy: 0.5031\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.4393 - accuracy: 0.8874 - val_loss: 2.4030 - val_accuracy: 0.5003\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.4294 - accuracy: 0.8917 - val_loss: 2.3983 - val_accuracy: 0.5154\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4198 - accuracy: 0.8948 - val_loss: 2.7955 - val_accuracy: 0.4732\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4135 - accuracy: 0.8967 - val_loss: 2.4386 - val_accuracy: 0.5040\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.4116 - accuracy: 0.8958 - val_loss: 2.4811 - val_accuracy: 0.4991\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.4074 - accuracy: 0.8976 - val_loss: 2.6104 - val_accuracy: 0.4929\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3873 - accuracy: 0.9042 - val_loss: 2.4740 - val_accuracy: 0.5138\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.3863 - accuracy: 0.9042 - val_loss: 2.7346 - val_accuracy: 0.4868\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.3789 - accuracy: 0.9067 - val_loss: 2.6896 - val_accuracy: 0.4948\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.3673 - accuracy: 0.9099 - val_loss: 2.7622 - val_accuracy: 0.4840\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3669 - accuracy: 0.9095 - val_loss: 2.6830 - val_accuracy: 0.5062\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.3637 - accuracy: 0.9108 - val_loss: 2.5127 - val_accuracy: 0.5108\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.3586 - accuracy: 0.9116 - val_loss: 2.7268 - val_accuracy: 0.4963\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3486 - accuracy: 0.9142 - val_loss: 2.8311 - val_accuracy: 0.4966\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3520 - accuracy: 0.9139 - val_loss: 2.7694 - val_accuracy: 0.5015\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.3417 - accuracy: 0.9183 - val_loss: 2.6948 - val_accuracy: 0.5062\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3359 - accuracy: 0.9200 - val_loss: 2.8059 - val_accuracy: 0.4926\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.3345 - accuracy: 0.9195 - val_loss: 2.7276 - val_accuracy: 0.5062\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3279 - accuracy: 0.9207 - val_loss: 2.8088 - val_accuracy: 0.5083\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.3262 - accuracy: 0.9213 - val_loss: 2.7612 - val_accuracy: 0.5006\n",
      "Epoch 59/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3241 - accuracy: 0.9214 - val_loss: 2.8637 - val_accuracy: 0.5129\n",
      "Epoch 60/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.3127 - accuracy: 0.9263 - val_loss: 2.8916 - val_accuracy: 0.5028\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 987us/step - loss: 2.6451 - accuracy: 0.2015 - val_loss: 2.3128 - val_accuracy: 0.3095\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 2.1991 - accuracy: 0.3347 - val_loss: 2.0836 - val_accuracy: 0.3932\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.9585 - accuracy: 0.4145 - val_loss: 1.9515 - val_accuracy: 0.4615\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.7853 - accuracy: 0.4709 - val_loss: 1.7357 - val_accuracy: 0.5320\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.6458 - accuracy: 0.5104 - val_loss: 1.6711 - val_accuracy: 0.5209\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 1.5259 - accuracy: 0.5475 - val_loss: 1.5944 - val_accuracy: 0.5551\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.4201 - accuracy: 0.5798 - val_loss: 1.5411 - val_accuracy: 0.5665\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 1.3435 - accuracy: 0.6002 - val_loss: 1.5319 - val_accuracy: 0.5705\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.2713 - accuracy: 0.6224 - val_loss: 1.4443 - val_accuracy: 0.5751\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.2018 - accuracy: 0.6469 - val_loss: 1.4341 - val_accuracy: 0.5926\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.1382 - accuracy: 0.6635 - val_loss: 1.3748 - val_accuracy: 0.6015\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 1.0831 - accuracy: 0.6788 - val_loss: 1.4065 - val_accuracy: 0.5975\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.0289 - accuracy: 0.6999 - val_loss: 1.4267 - val_accuracy: 0.5948\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.9830 - accuracy: 0.7117 - val_loss: 1.3597 - val_accuracy: 0.6117\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.9336 - accuracy: 0.7278 - val_loss: 1.3744 - val_accuracy: 0.6077\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.8870 - accuracy: 0.7426 - val_loss: 1.5622 - val_accuracy: 0.5683\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.8539 - accuracy: 0.7526 - val_loss: 1.4474 - val_accuracy: 0.6012uracy: \n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.8124 - accuracy: 0.7657 - val_loss: 1.4957 - val_accuracy: 0.5988\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.7868 - accuracy: 0.7722 - val_loss: 1.4938 - val_accuracy: 0.5978\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.7527 - accuracy: 0.7859 - val_loss: 1.4733 - val_accuracy: 0.6012\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.7155 - accuracy: 0.7959 - val_loss: 1.5185 - val_accuracy: 0.5966\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6976 - accuracy: 0.8015 - val_loss: 1.5479 - val_accuracy: 0.6025\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.6749 - accuracy: 0.8088 - val_loss: 1.5444 - val_accuracy: 0.6031\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6506 - accuracy: 0.8183 - val_loss: 1.5918 - val_accuracy: 0.5948\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.6280 - accuracy: 0.8260 - val_loss: 1.5435 - val_accuracy: 0.6120\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.6069 - accuracy: 0.8320 - val_loss: 1.5588 - val_accuracy: 0.6089\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5904 - accuracy: 0.8374 - val_loss: 1.6538 - val_accuracy: 0.5994\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.5754 - accuracy: 0.8428 - val_loss: 1.6380 - val_accuracy: 0.6025\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.5496 - accuracy: 0.8515 - val_loss: 1.5791 - val_accuracy: 0.6197\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.5389 - accuracy: 0.8549 - val_loss: 1.7011 - val_accuracy: 0.6058\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.5427 - accuracy: 0.8538 - val_loss: 1.6598 - val_accuracy: 0.6172\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.5083 - accuracy: 0.8671 - val_loss: 1.8022 - val_accuracy: 0.5886\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5066 - accuracy: 0.8658 - val_loss: 1.6971 - val_accuracy: 0.6271\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4920 - accuracy: 0.8696 - val_loss: 1.7798 - val_accuracy: 0.6009\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4670 - accuracy: 0.8792 - val_loss: 1.8461 - val_accuracy: 0.6037\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4736 - accuracy: 0.8752 - val_loss: 1.8723 - val_accuracy: 0.5975\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4602 - accuracy: 0.8782 - val_loss: 1.7413 - val_accuracy: 0.6163\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.4459 - accuracy: 0.8847 - val_loss: 1.7609 - val_accuracy: 0.6283\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4394 - accuracy: 0.8857 - val_loss: 1.8677 - val_accuracy: 0.6074\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.4239 - accuracy: 0.8924 - val_loss: 1.8405 - val_accuracy: 0.6191\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.4130 - accuracy: 0.8944 - val_loss: 1.8518 - val_accuracy: 0.6102\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.4128 - accuracy: 0.8938 - val_loss: 1.8398 - val_accuracy: 0.6188\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4018 - accuracy: 0.8989 - val_loss: 1.8731 - val_accuracy: 0.6188\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.3982 - accuracy: 0.9004 - val_loss: 2.0993 - val_accuracy: 0.5942\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3817 - accuracy: 0.9041 - val_loss: 1.9488 - val_accuracy: 0.6083\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3824 - accuracy: 0.9052 - val_loss: 2.1266 - val_accuracy: 0.5843\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3728 - accuracy: 0.9079 - val_loss: 2.1013 - val_accuracy: 0.5960\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3643 - accuracy: 0.9101 - val_loss: 2.1151 - val_accuracy: 0.5815\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.3550 - accuracy: 0.9121 - val_loss: 1.9681 - val_accuracy: 0.6215\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3570 - accuracy: 0.9111 - val_loss: 2.0460 - val_accuracy: 0.6052\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3489 - accuracy: 0.9134 - val_loss: 2.2986 - val_accuracy: 0.5695\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3461 - accuracy: 0.9145 - val_loss: 2.1914 - val_accuracy: 0.6022\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3345 - accuracy: 0.9176 - val_loss: 2.2139 - val_accuracy: 0.5791\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3321 - accuracy: 0.9165 - val_loss: 2.2183 - val_accuracy: 0.5969\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3243 - accuracy: 0.9199 - val_loss: 2.1297 - val_accuracy: 0.5997\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3223 - accuracy: 0.9199 - val_loss: 2.1409 - val_accuracy: 0.6138\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3239 - accuracy: 0.9190 - val_loss: 2.0688 - val_accuracy: 0.6105\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3173 - accuracy: 0.9209 - val_loss: 2.2295 - val_accuracy: 0.5985\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 995us/step - loss: 2.6598 - accuracy: 0.1985 - val_loss: 2.1723 - val_accuracy: 0.37426\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 2.2394 - accuracy: 0.3211 - val_loss: 1.9203 - val_accuracy: 0.4972\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 2.0004 - accuracy: 0.3995 - val_loss: 1.6833 - val_accuracy: 0.5809\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.8129 - accuracy: 0.4631 - val_loss: 1.5118 - val_accuracy: 0.6246\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.6647 - accuracy: 0.5090 - val_loss: 1.3796 - val_accuracy: 0.6618\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.5390 - accuracy: 0.5478 - val_loss: 1.2480 - val_accuracy: 0.6951\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.4271 - accuracy: 0.5826 - val_loss: 1.2338 - val_accuracy: 0.6806\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 1.3423 - accuracy: 0.6074 - val_loss: 1.1479 - val_accuracy: 0.6985\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.2608 - accuracy: 0.6304 - val_loss: 1.1135 - val_accuracy: 0.7052\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.1933 - accuracy: 0.6539 - val_loss: 1.1332 - val_accuracy: 0.6966\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.1285 - accuracy: 0.6728 - val_loss: 1.0970 - val_accuracy: 0.6985\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.0742 - accuracy: 0.6873 - val_loss: 1.0466 - val_accuracy: 0.7191\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.0269 - accuracy: 0.7030 - val_loss: 1.0255 - val_accuracy: 0.7172\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.9746 - accuracy: 0.7144 - val_loss: 1.0524 - val_accuracy: 0.7108\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.9277 - accuracy: 0.7302 - val_loss: 1.0191 - val_accuracy: 0.7218\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.8829 - accuracy: 0.7428 - val_loss: 1.0196 - val_accuracy: 0.7258\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.8513 - accuracy: 0.7544 - val_loss: 1.0321 - val_accuracy: 0.7160\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.8102 - accuracy: 0.7685 - val_loss: 1.0514 - val_accuracy: 0.7178\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.7807 - accuracy: 0.7761 - val_loss: 1.0651 - val_accuracy: 0.7203\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.7511 - accuracy: 0.7841 - val_loss: 1.1533 - val_accuracy: 0.6932\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.7230 - accuracy: 0.7961 - val_loss: 1.0428 - val_accuracy: 0.7289\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.6921 - accuracy: 0.8021 - val_loss: 1.0874 - val_accuracy: 0.7218\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.6655 - accuracy: 0.8094 - val_loss: 1.1337 - val_accuracy: 0.7203\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.6487 - accuracy: 0.8168 - val_loss: 1.2311 - val_accuracy: 0.6957\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.6245 - accuracy: 0.8213 - val_loss: 1.1880 - val_accuracy: 0.6929\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.6081 - accuracy: 0.8285 - val_loss: 1.1757 - val_accuracy: 0.7031\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5919 - accuracy: 0.8326 - val_loss: 1.1813 - val_accuracy: 0.7212\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.5722 - accuracy: 0.8399 - val_loss: 1.1816 - val_accuracy: 0.7105\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5616 - accuracy: 0.8447 - val_loss: 1.2219 - val_accuracy: 0.7105\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5451 - accuracy: 0.8465 - val_loss: 1.2137 - val_accuracy: 0.7077\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.5314 - accuracy: 0.8525 - val_loss: 1.2333 - val_accuracy: 0.7077\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5180 - accuracy: 0.8578 - val_loss: 1.2617 - val_accuracy: 0.7028\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5073 - accuracy: 0.8610 - val_loss: 1.2417 - val_accuracy: 0.7135\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4954 - accuracy: 0.8648 - val_loss: 1.3364 - val_accuracy: 0.6988\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4798 - accuracy: 0.8708 - val_loss: 1.3338 - val_accuracy: 0.7009\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4859 - accuracy: 0.8675 - val_loss: 1.2789 - val_accuracy: 0.7169\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4706 - accuracy: 0.8707 - val_loss: 1.3600 - val_accuracy: 0.6966\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4578 - accuracy: 0.8777 - val_loss: 1.4024 - val_accuracy: 0.7071\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4527 - accuracy: 0.8779 - val_loss: 1.4171 - val_accuracy: 0.6920\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4368 - accuracy: 0.8841 - val_loss: 1.3373 - val_accuracy: 0.6942\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4305 - accuracy: 0.8871 - val_loss: 1.4204 - val_accuracy: 0.6991\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 988us/step - loss: 2.6590 - accuracy: 0.2046 - val_loss: 2.1711 - val_accuracy: 0.4055\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 2.2292 - accuracy: 0.3222 - val_loss: 1.8736 - val_accuracy: 0.4982\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.9919 - accuracy: 0.3983 - val_loss: 1.6655 - val_accuracy: 0.5997\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.8171 - accuracy: 0.4576 - val_loss: 1.4687 - val_accuracy: 0.6462\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.6786 - accuracy: 0.5043 - val_loss: 1.3690 - val_accuracy: 0.6662\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.5583 - accuracy: 0.5409 - val_loss: 1.2319 - val_accuracy: 0.6945\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.4470 - accuracy: 0.5745 - val_loss: 1.2479 - val_accuracy: 0.6498\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 1.3766 - accuracy: 0.5937 - val_loss: 1.1624 - val_accuracy: 0.6929\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.2868 - accuracy: 0.6250 - val_loss: 1.0776 - val_accuracy: 0.7132\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 1.2203 - accuracy: 0.6426 - val_loss: 1.0432 - val_accuracy: 0.7138\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 1.1522 - accuracy: 0.6664 - val_loss: 0.9877 - val_accuracy: 0.7338\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 1.0976 - accuracy: 0.6798 - val_loss: 1.0057 - val_accuracy: 0.7255\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 1.0450 - accuracy: 0.6938 - val_loss: 0.9392 - val_accuracy: 0.7425\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.9937 - accuracy: 0.7100 - val_loss: 0.9536 - val_accuracy: 0.7452\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.9509 - accuracy: 0.7232 - val_loss: 0.9864 - val_accuracy: 0.7351\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.9077 - accuracy: 0.7356 - val_loss: 0.9452 - val_accuracy: 0.7425\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.8735 - accuracy: 0.7462 - val_loss: 0.9412 - val_accuracy: 0.7338\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.8401 - accuracy: 0.7556 - val_loss: 0.9711 - val_accuracy: 0.7388\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.8248 - accuracy: 0.7599 - val_loss: 0.9107 - val_accuracy: 0.7529\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.7759 - accuracy: 0.7763 - val_loss: 1.0258 - val_accuracy: 0.7317\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.7577 - accuracy: 0.7818 - val_loss: 0.9721 - val_accuracy: 0.7415\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.7161 - accuracy: 0.7924 - val_loss: 0.9757 - val_accuracy: 0.7369\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.6943 - accuracy: 0.7988 - val_loss: 0.9810 - val_accuracy: 0.7385\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.6774 - accuracy: 0.8053 - val_loss: 0.9971 - val_accuracy: 0.7440\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.6541 - accuracy: 0.8124 - val_loss: 1.0011 - val_accuracy: 0.7554- loss: 0.6539 - accuracy: 0.\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.6296 - accuracy: 0.8202 - val_loss: 1.0035 - val_accuracy: 0.7523\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.6212 - accuracy: 0.8218 - val_loss: 1.0430 - val_accuracy: 0.7483\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.5954 - accuracy: 0.8306 - val_loss: 1.0371 - val_accuracy: 0.7477\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.5802 - accuracy: 0.8359 - val_loss: 1.0288 - val_accuracy: 0.7440\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.5637 - accuracy: 0.8387 - val_loss: 0.9978 - val_accuracy: 0.7572\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5496 - accuracy: 0.8443 - val_loss: 1.0706 - val_accuracy: 0.7375\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5375 - accuracy: 0.8500 - val_loss: 1.0805 - val_accuracy: 0.7489\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.5236 - accuracy: 0.8513 - val_loss: 1.0784 - val_accuracy: 0.7400\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.5143 - accuracy: 0.8567 - val_loss: 1.1176 - val_accuracy: 0.7446\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.4976 - accuracy: 0.8634 - val_loss: 1.0839 - val_accuracy: 0.7474\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.5075 - accuracy: 0.8575 - val_loss: 1.0582 - val_accuracy: 0.7612\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4805 - accuracy: 0.8688 - val_loss: 1.1358 - val_accuracy: 0.7428\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4661 - accuracy: 0.8739 - val_loss: 1.1243 - val_accuracy: 0.7492\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4574 - accuracy: 0.8744 - val_loss: 1.1324 - val_accuracy: 0.7434\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.4517 - accuracy: 0.8774 - val_loss: 1.1467 - val_accuracy: 0.7483\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.4384 - accuracy: 0.8827 - val_loss: 1.0993 - val_accuracy: 0.7646\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.4299 - accuracy: 0.8862 - val_loss: 1.1864 - val_accuracy: 0.7443\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.4175 - accuracy: 0.8902 - val_loss: 1.2042 - val_accuracy: 0.7372\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.4165 - accuracy: 0.8891 - val_loss: 1.2010 - val_accuracy: 0.7455\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.4243 - accuracy: 0.8860 - val_loss: 1.1136 - val_accuracy: 0.7738\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4021 - accuracy: 0.8942 - val_loss: 1.2228 - val_accuracy: 0.7452\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3868 - accuracy: 0.8990 - val_loss: 1.1471 - val_accuracy: 0.7606\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3764 - accuracy: 0.9018 - val_loss: 1.1240 - val_accuracy: 0.7662\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3764 - accuracy: 0.9012 - val_loss: 1.1826 - val_accuracy: 0.7594\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.3710 - accuracy: 0.9048 - val_loss: 1.1838 - val_accuracy: 0.7551\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3609 - accuracy: 0.9079 - val_loss: 1.1773 - val_accuracy: 0.7594\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3551 - accuracy: 0.9090 - val_loss: 1.3731 - val_accuracy: 0.7385\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.3500 - accuracy: 0.9106 - val_loss: 1.2375 - val_accuracy: 0.7526\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3528 - accuracy: 0.9095 - val_loss: 1.2594 - val_accuracy: 0.7560\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.3452 - accuracy: 0.9109 - val_loss: 1.2789 - val_accuracy: 0.7468\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.3409 - accuracy: 0.9132 - val_loss: 1.2788 - val_accuracy: 0.7520\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.3352 - accuracy: 0.9147 - val_loss: 1.3470 - val_accuracy: 0.7483\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.3300 - accuracy: 0.9168 - val_loss: 1.3320 - val_accuracy: 0.7425\n",
      "Epoch 59/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3208 - accuracy: 0.9194 - val_loss: 1.3899 - val_accuracy: 0.7400\n",
      "Epoch 60/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.3265 - accuracy: 0.9168 - val_loss: 1.3019 - val_accuracy: 0.7492\n",
      "Epoch 61/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.3117 - accuracy: 0.9212 - val_loss: 1.3171 - val_accuracy: 0.7523\n",
      "Epoch 62/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.3072 - accuracy: 0.9230 - val_loss: 1.3874 - val_accuracy: 0.7462\n",
      "Epoch 63/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.2991 - accuracy: 0.9261 - val_loss: 1.3284 - val_accuracy: 0.7523\n",
      "Epoch 64/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3093 - accuracy: 0.9217 - val_loss: 1.3268 - val_accuracy: 0.7529\n",
      "Epoch 65/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.3093 - accuracy: 0.9221 - val_loss: 1.3043 - val_accuracy: 0.7585\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 994us/step - loss: 2.6572 - accuracy: 0.2036 - val_loss: 2.0924 - val_accuracy: 0.4415\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 2.2382 - accuracy: 0.3232 - val_loss: 1.7513 - val_accuracy: 0.5415\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 2.0054 - accuracy: 0.3916 - val_loss: 1.5580 - val_accuracy: 0.6092\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.8304 - accuracy: 0.4555 - val_loss: 1.3602 - val_accuracy: 0.6809\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 1.6933 - accuracy: 0.5011 - val_loss: 1.2422 - val_accuracy: 0.7040\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.5686 - accuracy: 0.5386 - val_loss: 1.1312 - val_accuracy: 0.7298\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.4625 - accuracy: 0.5703 - val_loss: 1.0415 - val_accuracy: 0.7511\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.3799 - accuracy: 0.5935 - val_loss: 0.9428 - val_accuracy: 0.7812\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.2916 - accuracy: 0.6209 - val_loss: 0.9363 - val_accuracy: 0.7588\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.2166 - accuracy: 0.6451 - val_loss: 0.8691 - val_accuracy: 0.7843\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.1561 - accuracy: 0.6634 - val_loss: 0.8332 - val_accuracy: 0.7880\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.1003 - accuracy: 0.6817 - val_loss: 0.7924 - val_accuracy: 0.7862\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 1.0437 - accuracy: 0.6988 - val_loss: 0.7888 - val_accuracy: 0.7874\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.9889 - accuracy: 0.7143 - val_loss: 0.7742 - val_accuracy: 0.7892\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.9434 - accuracy: 0.7283 - val_loss: 0.7510 - val_accuracy: 0.8003\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.8971 - accuracy: 0.7438 - val_loss: 0.7384 - val_accuracy: 0.8012\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.8585 - accuracy: 0.7539 - val_loss: 0.7066 - val_accuracy: 0.8095\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.8163 - accuracy: 0.7666 - val_loss: 0.7951 - val_accuracy: 0.7886\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.7893 - accuracy: 0.7744 - val_loss: 0.7452 - val_accuracy: 0.8031\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.7566 - accuracy: 0.7859 - val_loss: 0.7338 - val_accuracy: 0.8022\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.7291 - accuracy: 0.7957 - val_loss: 0.7667 - val_accuracy: 0.7988\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.6985 - accuracy: 0.8048 - val_loss: 0.7219 - val_accuracy: 0.8169\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.6749 - accuracy: 0.8124 - val_loss: 0.7850 - val_accuracy: 0.7966\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.6694 - accuracy: 0.8136 - val_loss: 0.7538 - val_accuracy: 0.8098\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.6269 - accuracy: 0.8282 - val_loss: 0.7667 - val_accuracy: 0.8058\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.6063 - accuracy: 0.8339 - val_loss: 0.7479 - val_accuracy: 0.8074\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.5839 - accuracy: 0.8422 - val_loss: 0.7687 - val_accuracy: 0.8071\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.5688 - accuracy: 0.8457 - val_loss: 0.8674 - val_accuracy: 0.7862\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.5561 - accuracy: 0.8506 - val_loss: 0.8823 - val_accuracy: 0.7825\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.5379 - accuracy: 0.8559 - val_loss: 0.8360 - val_accuracy: 0.7945\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.5232 - accuracy: 0.8626 - val_loss: 0.8895 - val_accuracy: 0.7969\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.5100 - accuracy: 0.8648 - val_loss: 0.8397 - val_accuracy: 0.8040\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4853 - accuracy: 0.8744 - val_loss: 0.8750 - val_accuracy: 0.8028\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4867 - accuracy: 0.8733 - val_loss: 0.8578 - val_accuracy: 0.8062\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4624 - accuracy: 0.8817 - val_loss: 0.8392 - val_accuracy: 0.8068\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.5137 - accuracy: 0.8632 - val_loss: 0.8070 - val_accuracy: 0.8169\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4426 - accuracy: 0.8866 - val_loss: 0.9432 - val_accuracy: 0.7975\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4346 - accuracy: 0.8892 - val_loss: 0.9301 - val_accuracy: 0.7991\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4167 - accuracy: 0.8952 - val_loss: 0.8132 - val_accuracy: 0.8191\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.4186 - accuracy: 0.8937 - val_loss: 0.9801 - val_accuracy: 0.7914\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.4090 - accuracy: 0.8976 - val_loss: 0.9359 - val_accuracy: 0.8022\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4063 - accuracy: 0.8984 - val_loss: 0.9500 - val_accuracy: 0.7935\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.4020 - accuracy: 0.8977 - val_loss: 0.9574 - val_accuracy: 0.7948l\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3939 - accuracy: 0.9004 - val_loss: 0.9405 - val_accuracy: 0.7994\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.3790 - accuracy: 0.9068 - val_loss: 0.9771 - val_accuracy: 0.7902\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3858 - accuracy: 0.9028 - val_loss: 0.9712 - val_accuracy: 0.7978\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3761 - accuracy: 0.9054 - val_loss: 0.9398 - val_accuracy: 0.7972\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3604 - accuracy: 0.9105 - val_loss: 0.9376 - val_accuracy: 0.8098\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3582 - accuracy: 0.9102 - val_loss: 0.9487 - val_accuracy: 0.8031\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3600 - accuracy: 0.9102 - val_loss: 1.0528 - val_accuracy: 0.7846\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3526 - accuracy: 0.9111 - val_loss: 0.9856 - val_accuracy: 0.7972\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3459 - accuracy: 0.9133 - val_loss: 0.9437 - val_accuracy: 0.8062\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3415 - accuracy: 0.9159 - val_loss: 1.0054 - val_accuracy: 0.8018\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.3346 - accuracy: 0.9164 - val_loss: 1.0529 - val_accuracy: 0.7917\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3408 - accuracy: 0.9137 - val_loss: 1.0737 - val_accuracy: 0.7902\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3222 - accuracy: 0.9200 - val_loss: 0.9948 - val_accuracy: 0.8012\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3197 - accuracy: 0.9220 - val_loss: 1.0194 - val_accuracy: 0.803494 - accura\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3193 - accuracy: 0.9212 - val_loss: 1.1138 - val_accuracy: 0.7748loss: 0.319\n",
      "Epoch 59/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3260 - accuracy: 0.9177 - val_loss: 1.0584 - val_accuracy: 0.7948\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 2.6546 - accuracy: 0.2022 - val_loss: 2.0678 - val_accuracy: 0.4554\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 982us/step - loss: 2.2390 - accuracy: 0.3197 - val_loss: 1.7226 - val_accuracy: 0.5486\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 2.0257 - accuracy: 0.3851 - val_loss: 1.5755 - val_accuracy: 0.5895\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.8550 - accuracy: 0.4453 - val_loss: 1.4003 - val_accuracy: 0.6855\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.7165 - accuracy: 0.4936 - val_loss: 1.2082 - val_accuracy: 0.7394\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.5913 - accuracy: 0.5326 - val_loss: 1.1210 - val_accuracy: 0.7409\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.4819 - accuracy: 0.5649 - val_loss: 1.0250 - val_accuracy: 0.7498\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.3968 - accuracy: 0.5891 - val_loss: 0.9531 - val_accuracy: 0.7871\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.3096 - accuracy: 0.6167 - val_loss: 0.9671 - val_accuracy: 0.7545\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.2353 - accuracy: 0.6405 - val_loss: 0.8234 - val_accuracy: 0.7905\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.1700 - accuracy: 0.6623 - val_loss: 0.8581 - val_accuracy: 0.7855\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 1.1193 - accuracy: 0.6770 - val_loss: 0.8184 - val_accuracy: 0.7969\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 1.0605 - accuracy: 0.6934 - val_loss: 0.7743 - val_accuracy: 0.7991\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 1.0112 - accuracy: 0.7078 - val_loss: 0.7760 - val_accuracy: 0.7966\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.9612 - accuracy: 0.7230 - val_loss: 0.7228 - val_accuracy: 0.8114\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 0.9174 - accuracy: 0.7344 - val_loss: 0.7202 - val_accuracy: 0.8095\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 0.8785 - accuracy: 0.7476 - val_loss: 0.7050 - val_accuracy: 0.8172\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.8387 - accuracy: 0.7600 - val_loss: 0.7074 - val_accuracy: 0.8157\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.8032 - accuracy: 0.7699 - val_loss: 0.7354 - val_accuracy: 0.8043\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.7738 - accuracy: 0.7810 - val_loss: 0.7189 - val_accuracy: 0.8169\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 58s 985us/step - loss: 0.7440 - accuracy: 0.7913 - val_loss: 0.7284 - val_accuracy: 0.8080\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.7141 - accuracy: 0.8001 - val_loss: 0.7535 - val_accuracy: 0.8117\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.6932 - accuracy: 0.8081 - val_loss: 0.7055 - val_accuracy: 0.8065\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.6633 - accuracy: 0.8156 - val_loss: 0.7374 - val_accuracy: 0.8114\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.6359 - accuracy: 0.8257 - val_loss: 0.7156 - val_accuracy: 0.8258\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.6143 - accuracy: 0.8330 - val_loss: 0.7305 - val_accuracy: 0.8197\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.5991 - accuracy: 0.8378 - val_loss: 0.7790 - val_accuracy: 0.8080\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.5815 - accuracy: 0.8425 - val_loss: 0.7730 - val_accuracy: 0.8123\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.5652 - accuracy: 0.8488 - val_loss: 0.7856 - val_accuracy: 0.8009\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.5488 - accuracy: 0.8528 - val_loss: 0.8049 - val_accuracy: 0.8108\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.5330 - accuracy: 0.8597 - val_loss: 0.8286 - val_accuracy: 0.8071\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.5167 - accuracy: 0.8641 - val_loss: 0.8243 - val_accuracy: 0.8123\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.5018 - accuracy: 0.8691 - val_loss: 0.8427 - val_accuracy: 0.8098\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4873 - accuracy: 0.8744 - val_loss: 0.8466 - val_accuracy: 0.8049\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.4714 - accuracy: 0.8793 - val_loss: 0.8304 - val_accuracy: 0.8080\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.4754 - accuracy: 0.8753 - val_loss: 0.8228 - val_accuracy: 0.8157\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.4615 - accuracy: 0.8829 - val_loss: 0.7915 - val_accuracy: 0.8126\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.4547 - accuracy: 0.8831 - val_loss: 0.8493 - val_accuracy: 0.8080\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.4364 - accuracy: 0.8893 - val_loss: 0.8209 - val_accuracy: 0.8172\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.4330 - accuracy: 0.8899 - val_loss: 0.8612 - val_accuracy: 0.8114\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.4124 - accuracy: 0.8968 - val_loss: 0.9223 - val_accuracy: 0.7923\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.4111 - accuracy: 0.8982 - val_loss: 0.8722 - val_accuracy: 0.8000\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4008 - accuracy: 0.9012 - val_loss: 0.8705 - val_accuracy: 0.8046\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3957 - accuracy: 0.9018 - val_loss: 0.8802 - val_accuracy: 0.8188\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.3896 - accuracy: 0.9034 - val_loss: 0.9016 - val_accuracy: 0.8083\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 991us/step - loss: 2.6598 - accuracy: 0.1981 - val_loss: 2.0787 - val_accuracy: 0.4314\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 2.2539 - accuracy: 0.3162 - val_loss: 1.7444 - val_accuracy: 0.5382\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 2.0306 - accuracy: 0.3862 - val_loss: 1.5210 - val_accuracy: 0.6486\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 1.8557 - accuracy: 0.4490 - val_loss: 1.3139 - val_accuracy: 0.7080\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 1.7143 - accuracy: 0.4916 - val_loss: 1.1803 - val_accuracy: 0.7323\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 1.5880 - accuracy: 0.5309 - val_loss: 1.0774 - val_accuracy: 0.7474\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 1.4807 - accuracy: 0.5611 - val_loss: 0.9829 - val_accuracy: 0.7668\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 1.3995 - accuracy: 0.5861 - val_loss: 0.9091 - val_accuracy: 0.7766\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 1.3119 - accuracy: 0.6136 - val_loss: 0.8450 - val_accuracy: 0.7849\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 1.2420 - accuracy: 0.6349 - val_loss: 0.8076 - val_accuracy: 0.8080\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 1.1808 - accuracy: 0.6516 - val_loss: 0.8228 - val_accuracy: 0.7843\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 1.1258 - accuracy: 0.6702 - val_loss: 0.7300 - val_accuracy: 0.8185\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 1.0696 - accuracy: 0.6861 - val_loss: 0.6843 - val_accuracy: 0.8274\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 1.0151 - accuracy: 0.7011 - val_loss: 0.7403 - val_accuracy: 0.7982\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.9715 - accuracy: 0.7143 - val_loss: 0.6939 - val_accuracy: 0.8105\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.9201 - accuracy: 0.7302 - val_loss: 0.7434 - val_accuracy: 0.8046\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.8803 - accuracy: 0.7389 - val_loss: 0.6714 - val_accuracy: 0.8258\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.8631 - accuracy: 0.7424 - val_loss: 0.6969 - val_accuracy: 0.8138\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.8106 - accuracy: 0.7622 - val_loss: 0.6927 - val_accuracy: 0.8132\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.7773 - accuracy: 0.7703 - val_loss: 0.6555 - val_accuracy: 0.8246\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.7511 - accuracy: 0.7774 - val_loss: 0.6732 - val_accuracy: 0.8185\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.7213 - accuracy: 0.7878 - val_loss: 0.6508 - val_accuracy: 0.8249\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.6982 - accuracy: 0.7957 - val_loss: 0.7013 - val_accuracy: 0.8225\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.6714 - accuracy: 0.8049 - val_loss: 0.7606 - val_accuracy: 0.8022\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.6464 - accuracy: 0.8114 - val_loss: 0.6676 - val_accuracy: 0.8283\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.6267 - accuracy: 0.8164 - val_loss: 0.6830 - val_accuracy: 0.8320\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.6211 - accuracy: 0.8200 - val_loss: 0.7103 - val_accuracy: 0.8209\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.5847 - accuracy: 0.8301 - val_loss: 0.7326 - val_accuracy: 0.8166\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.5673 - accuracy: 0.8360 - val_loss: 0.7099 - val_accuracy: 0.8252\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.5591 - accuracy: 0.8374 - val_loss: 0.7536 - val_accuracy: 0.8175\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.5525 - accuracy: 0.8408 - val_loss: 0.7264 - val_accuracy: 0.8206\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.5329 - accuracy: 0.8463 - val_loss: 0.7182 - val_accuracy: 0.8274\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.5185 - accuracy: 0.8500 - val_loss: 0.7194 - val_accuracy: 0.8305\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 56s 966us/step - loss: 0.5080 - accuracy: 0.8550 - val_loss: 0.8448 - val_accuracy: 0.8154\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.5026 - accuracy: 0.8574 - val_loss: 0.7369 - val_accuracy: 0.8228\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.4860 - accuracy: 0.8622 - val_loss: 0.7138 - val_accuracy: 0.8400\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 967us/step - loss: 0.4897 - accuracy: 0.8608 - val_loss: 0.7200 - val_accuracy: 0.8283\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 56s 960us/step - loss: 0.4719 - accuracy: 0.8682 - val_loss: 0.7274 - val_accuracy: 0.8415\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.4660 - accuracy: 0.8664 - val_loss: 0.6671 - val_accuracy: 0.8492\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 968us/step - loss: 0.4496 - accuracy: 0.8746 - val_loss: 0.6821 - val_accuracy: 0.8400\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.4441 - accuracy: 0.8764 - val_loss: 0.7380 - val_accuracy: 0.8360\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.4395 - accuracy: 0.8783 - val_loss: 0.7729 - val_accuracy: 0.8283\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.4228 - accuracy: 0.8830 - val_loss: 0.7324 - val_accuracy: 0.8372\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.4222 - accuracy: 0.8851 - val_loss: 0.7599 - val_accuracy: 0.8320\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.4208 - accuracy: 0.8841 - val_loss: 0.7673 - val_accuracy: 0.8320\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.4081 - accuracy: 0.8902 - val_loss: 0.7322 - val_accuracy: 0.8397\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.3966 - accuracy: 0.8945 - val_loss: 0.7379 - val_accuracy: 0.8422\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 56s 964us/step - loss: 0.3907 - accuracy: 0.8959 - val_loss: 0.7608 - val_accuracy: 0.8385\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 966us/step - loss: 0.3834 - accuracy: 0.8992 - val_loss: 0.7577 - val_accuracy: 0.8345\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.3819 - accuracy: 0.8998 - val_loss: 0.8130 - val_accuracy: 0.8308\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.3732 - accuracy: 0.9025 - val_loss: 0.8119 - val_accuracy: 0.8311\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.3632 - accuracy: 0.9086 - val_loss: 0.7696 - val_accuracy: 0.8391\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.3531 - accuracy: 0.9104 - val_loss: 0.7884 - val_accuracy: 0.8400\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 56s 963us/step - loss: 0.3483 - accuracy: 0.9132 - val_loss: 0.8240 - val_accuracy: 0.8268\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.3549 - accuracy: 0.9106 - val_loss: 0.7562 - val_accuracy: 0.8415\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 56s 961us/step - loss: 0.3344 - accuracy: 0.9168 - val_loss: 0.8197 - val_accuracy: 0.8317\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 56s 965us/step - loss: 0.3363 - accuracy: 0.9172 - val_loss: 0.7844 - val_accuracy: 0.8369\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.3195 - accuracy: 0.9219 - val_loss: 0.8239 - val_accuracy: 0.8434\n",
      "Epoch 59/150\n",
      "58500/58500 [==============================] - 56s 962us/step - loss: 0.3241 - accuracy: 0.9208 - val_loss: 0.8257 - val_accuracy: 0.8397\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 58s 995us/step - loss: 2.6664 - accuracy: 0.1990 - val_loss: 2.1907 - val_accuracy: 0.4028\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 2.2374 - accuracy: 0.3234 - val_loss: 1.7853 - val_accuracy: 0.5345\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 2.0087 - accuracy: 0.3938 - val_loss: 1.6072 - val_accuracy: 0.5769\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.8405 - accuracy: 0.4509 - val_loss: 1.3522 - val_accuracy: 0.6954\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 1.7054 - accuracy: 0.4943 - val_loss: 1.2074 - val_accuracy: 0.7249\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.5851 - accuracy: 0.5329 - val_loss: 1.0974 - val_accuracy: 0.7523\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 1.4718 - accuracy: 0.5649 - val_loss: 1.0160 - val_accuracy: 0.7698\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 1.3826 - accuracy: 0.5944 - val_loss: 0.9471 - val_accuracy: 0.7858\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 1.2996 - accuracy: 0.6194 - val_loss: 0.9225 - val_accuracy: 0.7828\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.2255 - accuracy: 0.6448 - val_loss: 0.8314 - val_accuracy: 0.8086\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.1563 - accuracy: 0.6657 - val_loss: 0.8426 - val_accuracy: 0.7945\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.1015 - accuracy: 0.6815 - val_loss: 0.7812 - val_accuracy: 0.7982\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.0489 - accuracy: 0.6975 - val_loss: 0.7855 - val_accuracy: 0.7963\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.0053 - accuracy: 0.7086 - val_loss: 0.7762 - val_accuracy: 0.8052\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 969us/step - loss: 0.9512 - accuracy: 0.7250 - val_loss: 0.7453 - val_accuracy: 0.8166\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.9114 - accuracy: 0.7352 - val_loss: 0.7307 - val_accuracy: 0.8191\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.8738 - accuracy: 0.7474 - val_loss: 0.6834 - val_accuracy: 0.8295\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.8352 - accuracy: 0.7591 - val_loss: 0.7258 - val_accuracy: 0.8132\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.7997 - accuracy: 0.7704 - val_loss: 0.7378 - val_accuracy: 0.8194\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.7701 - accuracy: 0.7775 - val_loss: 0.6662 - val_accuracy: 0.8345\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.7373 - accuracy: 0.7861 - val_loss: 0.7088 - val_accuracy: 0.8274\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.7154 - accuracy: 0.7939 - val_loss: 0.7477 - val_accuracy: 0.8185\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.6871 - accuracy: 0.8027 - val_loss: 0.7606 - val_accuracy: 0.8175\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 970us/step - loss: 0.6651 - accuracy: 0.8098 - val_loss: 0.7667 - val_accuracy: 0.8132\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.6489 - accuracy: 0.8165 - val_loss: 0.7519 - val_accuracy: 0.8228\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.6211 - accuracy: 0.8232 - val_loss: 0.7348 - val_accuracy: 0.8222\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.6075 - accuracy: 0.8281 - val_loss: 0.7789 - val_accuracy: 0.8163\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5885 - accuracy: 0.8338 - val_loss: 0.8215 - val_accuracy: 0.8185 accuracy: \n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5615 - accuracy: 0.8426 - val_loss: 0.7484 - val_accuracy: 0.8172\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.5434 - accuracy: 0.8508 - val_loss: 0.7238 - val_accuracy: 0.8289\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5363 - accuracy: 0.8534 - val_loss: 0.7846 - val_accuracy: 0.8295\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5216 - accuracy: 0.8571 - val_loss: 0.8329 - val_accuracy: 0.812010  - ETA: 0s - loss:\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.5113 - accuracy: 0.8608 - val_loss: 0.9057 - val_accuracy: 0.7966\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4983 - accuracy: 0.8645 - val_loss: 0.8215 - val_accuracy: 0.8222\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4901 - accuracy: 0.8684 - val_loss: 0.8275 - val_accuracy: 0.8252\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4745 - accuracy: 0.8742 - val_loss: 0.8177 - val_accuracy: 0.8231\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.4714 - accuracy: 0.8761 - val_loss: 0.7779 - val_accuracy: 0.8274\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4537 - accuracy: 0.8813 - val_loss: 0.8463 - val_accuracy: 0.8249\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.4381 - accuracy: 0.8861 - val_loss: 0.8661 - val_accuracy: 0.8154\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.4352 - accuracy: 0.8866 - val_loss: 0.8281 - val_accuracy: 0.8178\n",
      "Train on 58500 samples, validate on 3250 samples\n",
      "Epoch 1/150\n",
      "58500/58500 [==============================] - 59s 1ms/step - loss: 2.6387 - accuracy: 0.2061 - val_loss: 2.2988 - val_accuracy: 0.3129\n",
      "Epoch 2/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 2.2263 - accuracy: 0.3229 - val_loss: 1.9324 - val_accuracy: 0.4351\n",
      "Epoch 3/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 2.0074 - accuracy: 0.3938 - val_loss: 1.7271 - val_accuracy: 0.5218\n",
      "Epoch 4/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.8369 - accuracy: 0.4507 - val_loss: 1.5775 - val_accuracy: 0.6052\n",
      "Epoch 5/150\n",
      "58500/58500 [==============================] - 57s 982us/step - loss: 1.6970 - accuracy: 0.5004 - val_loss: 1.4621 - val_accuracy: 0.6268\n",
      "Epoch 6/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 1.5707 - accuracy: 0.5384 - val_loss: 1.3045 - val_accuracy: 0.6689\n",
      "Epoch 7/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 1.4617 - accuracy: 0.5719 - val_loss: 1.2650 - val_accuracy: 0.6680\n",
      "Epoch 8/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 1.3814 - accuracy: 0.5966 - val_loss: 1.1876 - val_accuracy: 0.6883\n",
      "Epoch 9/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 1.3030 - accuracy: 0.6177 - val_loss: 1.1220 - val_accuracy: 0.7006\n",
      "Epoch 10/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 1.2232 - accuracy: 0.6430 - val_loss: 1.0871 - val_accuracy: 0.7175\n",
      "Epoch 11/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 1.1597 - accuracy: 0.6622 - val_loss: 1.1430 - val_accuracy: 0.6865\n",
      "Epoch 12/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.1096 - accuracy: 0.6784 - val_loss: 1.0746 - val_accuracy: 0.7151\n",
      "Epoch 13/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 1.0528 - accuracy: 0.6940 - val_loss: 1.2868 - val_accuracy: 0.6720\n",
      "Epoch 14/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 1.0196 - accuracy: 0.7022 - val_loss: 1.0840 - val_accuracy: 0.7089\n",
      "Epoch 15/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.9601 - accuracy: 0.7192 - val_loss: 1.0818 - val_accuracy: 0.7212\n",
      "Epoch 16/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.9189 - accuracy: 0.7308 - val_loss: 1.0542 - val_accuracy: 0.7225\n",
      "Epoch 17/150\n",
      "58500/58500 [==============================] - 57s 983us/step - loss: 0.8752 - accuracy: 0.7438 - val_loss: 1.0950 - val_accuracy: 0.7108\n",
      "Epoch 18/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.8379 - accuracy: 0.7550 - val_loss: 1.0931 - val_accuracy: 0.7209\n",
      "Epoch 19/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.8058 - accuracy: 0.7643 - val_loss: 1.1047 - val_accuracy: 0.7080\n",
      "Epoch 20/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.7707 - accuracy: 0.7760 - val_loss: 1.0679 - val_accuracy: 0.7289\n",
      "Epoch 21/150\n",
      "58500/58500 [==============================] - 57s 973us/step - loss: 0.7407 - accuracy: 0.7828 - val_loss: 1.0967 - val_accuracy: 0.7126\n",
      "Epoch 22/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.7159 - accuracy: 0.7913 - val_loss: 1.1009 - val_accuracy: 0.72317153 - ac - ETA: 0s - loss: 0.7157 - accuracy\n",
      "Epoch 23/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.6837 - accuracy: 0.8019 - val_loss: 1.1705 - val_accuracy: 0.7154\n",
      "Epoch 24/150\n",
      "58500/58500 [==============================] - 57s 971us/step - loss: 0.6591 - accuracy: 0.8099 - val_loss: 1.1752 - val_accuracy: 0.7102\n",
      "Epoch 25/150\n",
      "58500/58500 [==============================] - 57s 972us/step - loss: 0.6365 - accuracy: 0.8165 - val_loss: 1.1199 - val_accuracy: 0.7317\n",
      "Epoch 26/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.6227 - accuracy: 0.8192 - val_loss: 1.1268 - val_accuracy: 0.7292\n",
      "Epoch 27/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.6051 - accuracy: 0.8263 - val_loss: 1.1954 - val_accuracy: 0.7108\n",
      "Epoch 28/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.5807 - accuracy: 0.8352 - val_loss: 1.2469 - val_accuracy: 0.7034\n",
      "Epoch 29/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.5673 - accuracy: 0.8368 - val_loss: 1.1621 - val_accuracy: 0.7366\n",
      "Epoch 30/150\n",
      "58500/58500 [==============================] - 57s 982us/step - loss: 0.5550 - accuracy: 0.8430 - val_loss: 1.1988 - val_accuracy: 0.7311\n",
      "Epoch 31/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.5377 - accuracy: 0.8496 - val_loss: 1.1687 - val_accuracy: 0.7391\n",
      "Epoch 32/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 0.5212 - accuracy: 0.8526 - val_loss: 1.2380 - val_accuracy: 0.7209\n",
      "Epoch 33/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.5163 - accuracy: 0.8561 - val_loss: 1.2998 - val_accuracy: 0.7209\n",
      "Epoch 34/150\n",
      "58500/58500 [==============================] - 57s 981us/step - loss: 0.4976 - accuracy: 0.8623 - val_loss: 1.2408 - val_accuracy: 0.7305\n",
      "Epoch 35/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.4853 - accuracy: 0.8676 - val_loss: 1.1759 - val_accuracy: 0.7382\n",
      "Epoch 36/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.4910 - accuracy: 0.8638 - val_loss: 1.2523 - val_accuracy: 0.7314\n",
      "Epoch 37/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.4602 - accuracy: 0.8767 - val_loss: 1.2454 - val_accuracy: 0.7372\n",
      "Epoch 38/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.4613 - accuracy: 0.8738 - val_loss: 1.4050 - val_accuracy: 0.7222\n",
      "Epoch 39/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.4636 - accuracy: 0.8742 - val_loss: 1.2789 - val_accuracy: 0.7188\n",
      "Epoch 40/150\n",
      "58500/58500 [==============================] - 57s 980us/step - loss: 0.4434 - accuracy: 0.8818 - val_loss: 1.2339 - val_accuracy: 0.7400\n",
      "Epoch 41/150\n",
      "58500/58500 [==============================] - 58s 998us/step - loss: 0.4233 - accuracy: 0.8886 - val_loss: 1.2702 - val_accuracy: 0.7332\n",
      "Epoch 42/150\n",
      "58500/58500 [==============================] - 58s 995us/step - loss: 0.4208 - accuracy: 0.8893 - val_loss: 1.2520 - val_accuracy: 0.7465\n",
      "Epoch 43/150\n",
      "58500/58500 [==============================] - 58s 991us/step - loss: 0.4172 - accuracy: 0.8908 - val_loss: 1.2651 - val_accuracy: 0.7354\n",
      "Epoch 44/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4178 - accuracy: 0.8902 - val_loss: 1.3296 - val_accuracy: 0.7317\n",
      "Epoch 45/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.4101 - accuracy: 0.8923 - val_loss: 1.2343 - val_accuracy: 0.7468\n",
      "Epoch 46/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.4019 - accuracy: 0.8967 - val_loss: 1.3535 - val_accuracy: 0.7249\n",
      "Epoch 47/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3848 - accuracy: 0.9025 - val_loss: 1.3822 - val_accuracy: 0.7240\n",
      "Epoch 48/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3786 - accuracy: 0.9043 - val_loss: 1.3118 - val_accuracy: 0.7369\n",
      "Epoch 49/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3796 - accuracy: 0.9034 - val_loss: 1.3315 - val_accuracy: 0.7255\n",
      "Epoch 50/150\n",
      "58500/58500 [==============================] - 57s 979us/step - loss: 0.3767 - accuracy: 0.9043 - val_loss: 1.3824 - val_accuracy: 0.7289\n",
      "Epoch 51/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3626 - accuracy: 0.9092 - val_loss: 1.3268 - val_accuracy: 0.7428\n",
      "Epoch 52/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.3604 - accuracy: 0.9104 - val_loss: 1.4242 - val_accuracy: 0.7320\n",
      "Epoch 53/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3565 - accuracy: 0.9128 - val_loss: 1.3878 - val_accuracy: 0.7157\n",
      "Epoch 54/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3468 - accuracy: 0.9143 - val_loss: 1.3804 - val_accuracy: 0.7372\n",
      "Epoch 55/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3420 - accuracy: 0.9151 - val_loss: 1.4234 - val_accuracy: 0.7234\n",
      "Epoch 56/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.3386 - accuracy: 0.9151 - val_loss: 1.3487 - val_accuracy: 0.7418\n",
      "Epoch 57/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3420 - accuracy: 0.9154 - val_loss: 1.4520 - val_accuracy: 0.7345\n",
      "Epoch 58/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3295 - accuracy: 0.9191 - val_loss: 1.4690 - val_accuracy: 0.7262\n",
      "Epoch 59/150\n",
      "58500/58500 [==============================] - 57s 977us/step - loss: 0.3229 - accuracy: 0.9209 - val_loss: 1.3936 - val_accuracy: 0.7243\n",
      "Epoch 60/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.3252 - accuracy: 0.9192 - val_loss: 1.3843 - val_accuracy: 0.7354\n",
      "Epoch 61/150\n",
      "58500/58500 [==============================] - 57s 976us/step - loss: 0.3122 - accuracy: 0.9248 - val_loss: 1.3328 - val_accuracy: 0.7388\n",
      "Epoch 62/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.3121 - accuracy: 0.9239 - val_loss: 1.3511 - val_accuracy: 0.7409\n",
      "Epoch 63/150\n",
      "58500/58500 [==============================] - 57s 975us/step - loss: 0.3033 - accuracy: 0.9264 - val_loss: 1.6546 - val_accuracy: 0.7095\n",
      "Epoch 64/150\n",
      "58500/58500 [==============================] - 57s 974us/step - loss: 0.3109 - accuracy: 0.9247 - val_loss: 1.3481 - val_accuracy: 0.7394\n",
      "Epoch 65/150\n",
      "58500/58500 [==============================] - 57s 978us/step - loss: 0.3033 - accuracy: 0.9267 - val_loss: 1.5855 - val_accuracy: 0.7194\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speeds):\n",
    "    data_set = dir_temp + rf\"/{i}\"\n",
    "    X_train = open_obj(data_set + r\"/X_train_RA\")\n",
    "    X_val = open_obj(data_set + r\"/X_val_RA\")\n",
    "    y_train = open_obj(data_set + r\"/y_train_RA\")\n",
    "    y_val = open_obj(data_set + r\"/y_val_RA\")\n",
    "    \n",
    "    dir_model = dir_data + rf\"/models/dynamic_RA/{i}\"\n",
    "    os.makedirs(dir_model)\n",
    "    cp = callbacks.ModelCheckpoint(dir_model + r\"/model_{epoch:02d}_{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True)\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "    define_model(X_train, y_train[1], X_val, y_val[1], es, cp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
